{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Introduction to Natural Language Processing </center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> What is NLP? </h2> </font> \n",
    "* One of the most challenging and revolutionary things artificial intelligence (AI) can do is speak, write, listen, and understand human language. Natural language processing (NLP) is a form of AI that extracts meaning from human language to make decisions based on the information.  \n",
    "<br>\n",
    "* It is an interdisciplinary field which draws on other areas of study sucj as computer science , Artificial Intelligence, linguistics and logic.\n",
    "\n",
    "<img src=\"images/image001.png\", width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Why NLP Understanding is hard? </h2> </font> \n",
    "* Natural language is extremely rich in form and structure, and very ambiguous.\n",
    "    - How to represent meaning\n",
    "    - Which structures map to which meaning structures.  \n",
    "<br>\n",
    "* One input can mean many different things. Ambiguity can be at different levels.\n",
    "    - Lexical (word level) ambiguity  -- different meanings of words\n",
    "    - Syntactic ambiguity  --  different ways to parse the sentence\n",
    "    - Interpreting partial information  --  how to interpret pronouns\n",
    "    - Contextual information  --  context of the sentence may affect the meaning of that sentence.  \n",
    "<br>\n",
    "* Many input can mean the same thing.  \n",
    "<br>\n",
    "* Interaction among components of the input is not clear. \n",
    "<img src=\"images/image002.png\", width=300>\n",
    "\n",
    "**What Applications of NLP can you think of?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> NLP Applications </h2> </font> \n",
    "<img src=\"images/machine_translation.png\">\n",
    "* Famous application: **Google Translate**\n",
    "<img src=\"images/Picture1.png\">\n",
    "* Movie Reviews: **Positive of Negative**\n",
    "<img src=\"images/Picture2.png\">\n",
    "* Classification of emails: **Important, Spam, etc**\n",
    "<img src=\"images/Picture3.png\">\n",
    "<font> <h3> Speech recognition (Speech-to-text) and Speech Understanding </h3> </font> \n",
    "<img src=\"images/speech_recog.jpeg\", width=300>\n",
    "* Famous application: **Amazon‚Äô s Alexa, Google‚Äôs Home, SIRI**\n",
    "<font> <h3> Text prediction </h3> </font> \n",
    "<img src=\"images/text_pred.png\", width=300>\n",
    "* Speed up word processing and Facilitate text dictation (seen in SMS and email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Overview</h2> </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Pipeline</h2> </font> \n",
    "<font color='black'> <h3>During this class we will work with an example. Write a review of a product of your choice and you will be able to run code examples on your review following the NLP pipeline described below</h3> </font> \n",
    "<img src=\"images/Capture.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Text Pre-processing - ¬†extracting the useful information from the textual data. </h2> </font> \n",
    "* Converting all letters to lower or upper case\n",
    "\n",
    "* Converting numbers into words or removing numbers\n",
    "\n",
    "* Removing punctuations, accent marks and other diacritics\n",
    "\n",
    "* Removing white spaces\n",
    "\n",
    "* Expanding abbreviations\n",
    "\n",
    "* Removing stop words, sparse terms, and particular words\n",
    "\n",
    "** Enter a positive or/and a negative review for a product of your choice and use the functins provided in the notebook to pre-process your review. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"data/nltk_data/\")\n",
    "!cd data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "def convert_to_lower(mytext):\n",
    "    return mytext.lower()\n",
    "def remove_numbers(mytext):\n",
    "    return ''.join([i for i in mytext if not i.isdigit()])\n",
    "def remove_puntuation(mytext):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return ' '.join([w.translate(table) for w in mytext.split()])\n",
    "def remove_white_spaces(mytext):\n",
    "    return ' '.join(mytext.strip().split())\n",
    "def remove_stop_words(mytext):\n",
    "    stop_words = list(stopwords.words('english')) \n",
    "    output =[]\n",
    "    for i in mytext.split():\n",
    "        if not i in stop_words:\n",
    "            output.append(i)\n",
    "    return ' '.join(output)\n",
    "def pre_process(mytext):\n",
    "    mytext_lower = convert_to_lower(mytext)\n",
    "    my_text_char = remove_numbers(mytext_lower)\n",
    "    my_text_no_punct = remove_puntuation(my_text_char)\n",
    "    my_text_white_spaces = remove_white_spaces(my_text_no_punct)\n",
    "    preprocessed_text = remove_stop_words(my_text_white_spaces)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> <h2> Write a product review below and test our pre-processing functions! </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertaining funny\n"
     ]
    }
   ],
   "source": [
    "# You can play with this. Change the texts between the quotes and call the functions to process/clean it! \n",
    "positive_review= \"Very entertaining and funny!\"\n",
    "processed_positive_review = pre_process(positive_review)\n",
    "print(processed_positive_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>NLP Pipeline</h2> </font> \n",
    "<img src=\"images/Capture2.PNG\", width = 1100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2>How do we have usable meaning in a computer?</h2> </font> \n",
    "Definition: meaning (Webster dictionary)\n",
    "<br/>\n",
    "‚Ä¢ the idea that is represented by a word, phrase, etc.\n",
    "<br/>\n",
    "‚Ä¢ the idea that a person wants to express by using\n",
    "words, signs, etc.\n",
    "<br/>\n",
    "‚Ä¢ the idea that is expressed in a work of writing, art, etc.\n",
    "<br/>\n",
    "How do we represent words? Remember, the computer only understands numbers ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 1: Representing words as discrete symbols\n",
    "** Example: ** Very entertaining and funny!\n",
    "<br/>\n",
    "* We define the vocabulary: \n",
    "\\begin{align}\n",
    "\\mathcal V =\\{'entertaining','funny'\\}\\\\\n",
    "\\end{align}\n",
    "* Embeddings: \n",
    "\\begin{equation}\n",
    "  emb =\n",
    "    \\begin{cases}\n",
    "      X^{entertaining} = [1,0]\\\\\n",
    "      X^{funny} = [0,1]\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "* Vector dimension = number of words in vocabulary (e.g., 500,000)\n",
    "* This Method is called **<font color='red'>One Hot Encoding**: <br/>\n",
    "For a corpus ùê∂ with finite vocabulary, ùëâ and |ùëâ|=ùëõ.\n",
    "<br/> Let emb:ùëâ‚Üí‚Ñï√ó‚Ñï‚ãØ√ó‚Ñï‚âêùëâ¬†ÃÉ  be a map defined by taking every element in ùëâ to an ùëõ component object ùëã¬†‚Éó‚ààùëâ¬†ÃÉ\n",
    " such that: <br/>\n",
    "    \\begin{equation}\n",
    "  X_{i}^{w} =\n",
    "    \\begin{cases}\n",
    "      1, & \\text{if    } idx(w)=i \\\\\n",
    "      0,& \\text{otherwise}\\\\\n",
    "    \\end{cases}       \n",
    "\\end{equation}\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DEF_FIGLEN = 7\n",
    "DEF_FIGSIZE = (DEF_FIGLEN, DEF_FIGLEN)\n",
    "\n",
    "def figure(figsize=DEF_FIGSIZE):\n",
    "    return plt.figure(figsize=figsize)\n",
    "\n",
    "def new_blank_plot(ax=None, xlim=(-2, 2), ylim=(-2, 2), axis_color='gray', title=''):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        plt.sca(ax)\n",
    "    ax.axis('equal')\n",
    "    if xlim is not None: ax.set_xlim(xlim[0], xlim[1])\n",
    "    if ylim is not None: ax.set_ylim(ylim[0], ylim[1])\n",
    "    if axis_color is not None:\n",
    "        ax.axhline(color=axis_color)\n",
    "        ax.axvline(color=axis_color)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    return ax\n",
    "\n",
    "def vector(*elems, dim=None):\n",
    "    \"\"\"Exercise: What does this function do?\"\"\"\n",
    "    if dim is not None:\n",
    "        if len(elems) > 0:\n",
    "            assert dim == len(elems), \"Number of supplied elements differs from the requested dimension.\"\n",
    "        else: # No supplied elements\n",
    "            elems = [0.0] * dim\n",
    "    return tuple(elems)\n",
    "\n",
    "\n",
    "def draw_vector2d(v, ax=None, origin=(0, 0), width=0.08, color='black', alpha=1.0,\n",
    "                  **kw_args):\n",
    "    assert len(v) == 2, \"Input vector must be two-dimensional.\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.arrow(origin[0], origin[1], v[0], v[1],\n",
    "             width=width,\n",
    "             facecolor=color,\n",
    "             edgecolor='white',\n",
    "             alpha=alpha,\n",
    "             length_includes_head=True,\n",
    "             **kw_args);\n",
    "    \n",
    "def draw_label2d(p, label, coords=False, ax=None, fontsize=14,\n",
    "                 dp=(0.0, 0.1), horizontalalignment='center', verticalalignment='bottom',\n",
    "                 **kw_args):\n",
    "    assert len(p) == 2, \"Position must be 2-D.\"\n",
    "    if ax is None: ax = plt.gca()\n",
    "    text = '{}'.format(label)\n",
    "    if coords:\n",
    "        text += ' = ({}, {})'.format(p[0], p[1])\n",
    "    ax.text(p[0]+dp[0], p[1]+dp[1], text,\n",
    "            fontsize=fontsize,\n",
    "            horizontalalignment=horizontalalignment,\n",
    "            verticalalignment=verticalalignment,\n",
    "            **kw_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def discrete_word_representation(mytext):\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(mytext.split())\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    return onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vec = discrete_word_representation(processed_positive_review)\n",
    "one_hot_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAGrCAYAAAC7YyL8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xu4XOPd//HPV06SOJQkEolIqGOUSrOFiIcgSFGq5XLoD1GEFq0+1KF5SosqbfVIH42KkGpoeRBECXUI4rCjURIhQSRbEtlJiEPk/P39ca/pnr0zM3tmz+yZ2bnfr+uaK7PWute6v2tmZ3/2uteaNebuAgBgY7dJpQsAAKAcCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8bHTM7Cdm9pdK15FiZnPNbHjy/Edm9udK11RtzGycmV3TwnWfMrOzSl0TNj7tK10AEBN3v7bcfZrZXElnufvj5e4bqCYc4aHNsiDqn2Ez449WIE9R/7JA+ZjZGWb2YNr0HDP7W9r0fDPbO3m+v5m9bGbLk3/3T2v3lJn9zMyek7RC0o5mtoOZPW1mn5jZZEnd09pvamZ/MbOlZvZRsr2eWWq8zMzeTrYz08yOS1u2U9LHcjNbYmZ359jXU83svaTP0U2W/We4NVdtZra1md1mZgvM7EMzuz+ZP8zM6szsUjNbJOm2ZP7RZjY92c7zZrZXMn+8pO0lPWhmn5rZJcn8/ZJ2H5nZq2Y2LMf+XGpm7yevy5tmdqiZ9TKzFWbWLa3dIDOrN7MOZjbSzJ4zs98kfbyTvK8jk/d6sZmd3qSr7mY2OennaTPrl7btrD8TTWrN+31ChNydB49Wf0jaUdJHCn9kbSvpPUnvpy37MFm2dfL8VIUh95OT6W5J26ckzZO0R7K8g6Spkn4tqZOkAyV9IukvSftzJD0oqYukdpIGSdoiS40nSOqd1HGipM8kbZssmyBpdLJsU0kHZNnGAEmfJnV0SupaK2l4svwn+dQm6WFJd0vaKtnHg5L5w5LtXZ9sv7Okr0haLGnfZDunS5orqVOyztxU/8l0H0lLJR2Z7M9hyXSPDPuzq6T5knon0/0lfTF5PknSd9La/kbSH5LnI5M6z0hquiZ5325K6j48eZ82S9qPS6ZTr9vvJD2bLMvnZ+KsQt4nHnE+OMJDWbj7Owq/0PaWdJCkRyW9b2a7JdNT3H29pKMkzXb38e6+1t0nSJol6Wtpmxvn7jPcfa1CeO4j6cfuvsrdn1EIkZQ1krpJ2snd17n7NHf/OEuNf3f3Be6+3t3vljRb0uC07fRT+MW/0t2fzbKrx0t6yN2fcfdVkn4saX2WthlrM7NtJX1V0rnu/qG7r3H3p9PWWy/pymR/P5d0tqQ/ufuLyXZul7RK0n5Z+v1/kia5+6RkXydLqlUIwKbWKQTQADPr4O5z3f3tZNntybZkZu0Ugmh82rrvuvtt7r5OIbz7SroqqfsxSasl7ZTW/uG01220pCFm1lf5/Uykv6b5vE+IEIGHcnpa4QjlwOT5Uwphd1AyLYUjrPearPeewlFJyvy0570lfejunzVpnzJeIVzvSoYHf2FmHTIVZ2anpQ0LfiTpS2oYHr1Ekkl6ycxmmNm3s+xj7/T6krqWZmmbrba+kpa5+4dZ1qt395Vp0/0kXZSqO6m9b1JLJv0kndCk/QEKfzw04u5zJF2ocGS62MzuMrPUdh9QCMIdFY4Sl7v7S2mrf5D2/PNke03nbZY2nf66fSppWbIP+fxMpOT7PiFCBB7KKRV4/5U8f1obBt4ChV/I6baX9H7adPpXfCyUtJWZdW3SPjQMR0c/dfcBkvaXdLSk05oWlpwvukXS+QpDZV+Q9LrCL0+5+yJ3P9vdeysMRf7RzHZqup2knr5p2+2icBS3gRy1zZe0tZl9IdN6TfZfSfufufsX0h5dkiOhbO3HN2nf1d2vy1LnX939AIX3xRWGU5WE7t8kfUthuHF8pvULkP66baYwlLlA+f1MpGrN931ChAg8lNPTkg6W1Nnd6yRNkTRCIRD+lbSZJGkXMzvFzNqb2YkK58UeyrRBd39PYTjup2bW0cwOUNpQl5kdbGZ7JkNuHysMea3LsKmuCr/M65P1zlA4wktt5wQz2y6Z/DBpm2k790g62swOMLOOkq5Slv9n2Wpz94WSHlH4Zb1VchHIgZm2kbhF0rlmtq8FXc3sKDPbPFn+gcJ50pS/SPqamR1hZu0sXDwzLG3/0mvc1cwOMbNOklYqHJWl7/cdCufrjkm2W4wj0163qyW96O7zVcDPRAHvEyJE4KFs3P0thQs6piTTH0t6R9JzyXkeuftShSOdixSGAi+RdLS7L8mx6VMULthYJulKhV/CKb0UQuhjSW8ohO4Gv5jdfaakGxQugPlA0p6Snktrso+kF83sU0kTJX3f3d/NsJ0Zks6T9FeFo70PJdVlqTtXbacqBOAshQtSLsy28+5eq3Ae78akvzkKIZTyc0n/kwxfXpyEyLGSfqQQ8PMl/VCZfx90knSdpCWSFknaJlkv1fdzCucUX3H3udlqzNNfFd6/ZQoX8Hwr6aOQn4m83ifEydz5AlgALWdm/5T0V3fnDjKoagQegBYzs30kTZbU190/qXQ9QC4MaQJoETO7XdLjki4k7NAWcIQHAIgCR3gAgChU9Y1nu3fv7v379690GUBFLV0aPrferVvGj/MBUZk2bdoSd+/RknWrOvD69++v2traSpcBVNS4ceMkSSNHjqxoHUA1MLOmd93JG0OaAIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKJQk8MxsrJktNrPXsywfZmbLzWx68riiFP0CAJCv9iXazjhJN0q6I0ebKe5+dIn6AwCgICU5wnP3ZyQtK8W2AABoDeU8hzfEzF41s0fMbI9sjcxslJnVmlltfX19GcsDAGzMyhV4r0jq5+5flvQHSfdna+juY9y9xt1revToUabyAAAbu7IEnrt/7O6fJs8nSepgZt3L0TcAAFKZAs/MepmZJc8HJ/0uLUffAABIJbpK08wmSBomqbuZ1Um6UlIHSXL3myUdL+k7ZrZW0ueSTnJ3L0XfAADkoySB5+4nN7P8RoWPLQAAUBHcaQUAEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPbc/69dI550jduklm0lNPVbqi8nj6aWmXXaR16ypdSet56CFp773DewyUGIGHtmfSJOm226QHH5QWLpT237/SFZXHD38ojR4ttWvXMO/pp6VBg6RNN5V23FG6+ebmtzNvnvS1r0ldu0rdu0vf+560enVhtSxcKJ1yirTbbqGekSPzW+/DD6VTT5W23DI8Tj1V+uijhuVHHx22d+edhdUD5IHAQ9szZ4607bYh6Hr1kjp2rHRFra7H7NnSrFnSCSc0zHz3XenII8Pr8K9/SZdfLl1wgXTvvdk3tG6ddNRR0iefSFOmSBMmSPfcI110UWEFrVoVwvKyy6R9981/vVNOkV55RXrkEekf/wjPTz21cZszzpB+//vC6gHy4e5V+xg0aJADjZx+urvU8OjXL8w/6CD3887bsO1RRzVMH3SQ+3e+43755e7durn36OF+0UXu69Y1tOnXz/3qq91HjXLffHP3Pn3cf/GLhuVnnNF4m+5h/b593W+4oVR72chtt93mMw85xP244xovuOQS9512ajzvzDPd99sv+8YmTXI3c583r2He+PHunTq5L1/esgKPOiq81s2ZOTO8Z88+2zBvypQwb9ashnnvvRfmzZ7dsnqwUZNU6y3MFI7w0Lb87nfSFVdI220XhtVefrmw9e+8U2rfXnr+eenGG6Xf/la6++7GbX7zG2nPPcPRx6WXSpdcIk2dGpadfXY4Mlm4sKH95MnSokUbHqmk22yz3I+vfjVn2T1nz5ZqahrPnDpVOvzwxvOOOEKqrZXWrMm8oalTpd13l/r2bbzOqlXStGk5ayja1KlhX9OHoIcODUOrzz/fMG/77aWePcNwLVBC7StdAFCQLbeUNt88nOfp1avw9QcMkK66KjzfZRfpllukJ56QTj65oc3hh0vnnx+eX3BBGF574glpyJDw2G036fbbw3CeJI0dKx1zjNSjR/Z+p0/PXVfnzjkXb7ZkSRjGTbdokTR8eON5PXtKa9dKmdqn1unZs/G87t3D67loUe4ai7VoUXiNzBrmmUnbbLNh3717S3Pntm49iA6Bh7jstVfj6d69pcWLC2tz9tnSH/8YAm/ZMumBB6T77svd7047tbxmSe3WrAkXpjSVHh5SGOjNND/XOs3NL6VMfbhvOL9zZ+nzz1u/HkSFIU1sHDbZpOGXfUqmYb0OHRpPm214CXxzbU49VXrvPenZZ8MQaffuGw4tNlXkkObKzTYLVzim69VrwyOjxYvDkG23bpk3lGmdJUvCxSxNj/xKrVevUF/6++Qu1ddv2PeyZbmPmIEW4AgPG4cePRqfV5OkV1+V+vcvfV9bby194xthKPNf/wqX5Kd/VCCTIoc0l/Xrp64zZzaeOWSIdP/9jedNnhzO9TUN7fR1rrlGqqsL50FT63TqFD7e0JqGDJE+/TScy0udx5s6Vfrss8bn9VaulN5+W/rKV1q3HkSHwMPG4ZBDpAsvlCZOlHbdVfrTn6T581sn8KQwrDliRDiKvOee5tsXOaT5/pe+pL7PPtt45rnnhgtvLrwwfBD/ueekcePCRw1SbrwxPGbNCtOHHy7tsYd02mnSDTdIS5eGz/edfba0xRaFFZUK8Y8/DkfY06eHj4gMGBDm33df+KjEE09IffqEi2VGjAi13nJLOLo755zw2btdd23Y7gsvhAAeOrSweoBmMKSJjcO3v93wGDo0DBMed1zr9TdsWDhCGjZM+uIXW6+fxDtDhkhvvSXNmNEwc4cdwofwn3km3J3kZz8LF9h885sNbZYskd58s2G6XTvp4YelLl3C63TiieFo9Ve/amgzd24Yxh03LndRAweGx5Qp4SYAAweGzwWmLF8e+k4fWr7zTunLXw7Be8QR4fn48Y23O2GC9K1vhRqBEjJvet6jitTU1HhtbW2lywA29Pnn4ajlD38Iv5xb0bgkeEbOmhXOd916a6v2pyefDME1Y0a4e0s51deHq2Bra0OgA02Y2TR3r2m+5YY4wgMKsX59OFd45ZXhvFv6nU9a249+FAKote+lOWlS+PxhucNOCneP+eMfCTu0Cs7hAYWYNy/8Mt5uu3A/z3Le1myLLcK9NFvbL3/Z+n1kM3hweACtgMADCtG//4YffwDQJjCkCQCIAoEHAIgCgQcAiAKBBwCIAoEHAIhCSQLPzMaa2WIzez3LcjOz35vZHDP7t5lxkzwAQFmV6ghvnKQROZZ/VdLOyWOUpP8tUb8AAOSlJIHn7s9IWpajybGS7ki+of0FSV8wswzfTgkAQOso1zm8PpLmp03XJfM2YGajzKzWzGrr6+vLUhxQ1dat2/A7+wAUrFyBl+mrlDPersLdx7h7jbvX9OALIAHu7AKUSLkCr05S37Tp7SQtKFPfQNu1enW4WfXKlZWuBGjzyhV4EyWdllytuZ+k5e6+sLmVgOitWiUtXiwtWiStWFHpaoA2rSQ3jzazCZKGSepuZnWSrpTUQZLc/WZJkyQdKWmOpBWSzihFv8BGb8UK6dNPw5eoWqYzAwDyVZLAc/eTm1nuks4rRV9ANFavbvg28FWrwjeR7757RUsC2jLutAJUq1WrpAkTGqbHjmVYEygCgQdUqxUrpFdeaZj+298Y1gSKQOAB1Sh9ODNl3rwwrAmgRQg8oBo1Hc5MYVgTaDECD6hGTYczUxjWBFqMwAOqTabhzBSGNYEWI/CAapNtODOFYU2gRQg8oNpkG85MYVgTaBECD6gmuYYzUxjWBFqEwAOqSXPDmSkMawIFI/CAatLccGYKw5pAwQg8oFrkM5yZwrAmUDACD6gW+Q5npjCsCRSEwAOqRb7DmSkMawIFIfCAalDIcGYKw5pAQQg8oBoUOpyZwrAmkDcCD6gGhQ5npjCsCeSNwAMqrSXDmSkMawJ5I/CASmvpcGYKw5pAXgg8oNJaOpyZwrAmkBcCD6ikYoYzUxjWBPJC4AGVVOxwZgrDmkCzCDygkoodzkxhWBNoFoEHVEophjNTGNYEmkXgAZVSquHMFIY1gZwIPKBSSjWcmcKwJpATgQdUQimHM1MY1gRyIvCASij1cGYKw5pAVu0rXQAQpU6dpEMPlQ45JPPy8eOlDz7IvKymRho2LPOyPn0Y1gSyIPCASjCTrrkm87JNNpHatZOuvz7z8t//XtpnH2n9+uzrA9gAgQdUQocO2ZetXdv8+u35rwsUij8FAQBRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUShJ4JnZCDN708zmmNllGZaPNLN6M5uePM4qRb8AAOSr6PsTmVk7STdJOkxSnaSXzWyiu89s0vRudz+/2P4AAGiJUhzhDZY0x93fcffVku6SdGwJtgsAQMmUIvD6SJqfNl2XzGvqm2b2bzO7x8z6ZtuYmY0ys1ozq62vry9BeQAAlCbwMn35ljeZflBSf3ffS9Ljkm7PtjF3H+PuNe5e06NHjxKUBwBAaQKvTlL6Edt2khakN3D3pe6+Kpm8RdKgEvQLAEDeShF4L0va2cx2MLOOkk6SNDG9gZltmzZ5jKQ3StAvAAB5K/oqTXdfa2bnS3pUUjtJY919hpldJanW3SdK+p6ZHSNpraRlkkYW2y8AAIUoydcmu/skSZOazLsi7fnlki4vRV8AALQEd1oBAESBwAMARIHAAwBEgcADAESBwAMARIHAAwBEgcADAESBwAMARIHAAwBEgcADAESBwAMARIHAAwBEgcADAESBwAMARIHAAwBEgcADAESBwAMARIHAAwBEgcADAESBwAMARIHAA1D15s6VzKTa2vzXeeqpsM6SJa1VVWnNni317CktX17pSlrPa69JffpIn31Wmf4JPABZlTo0xo2TNtus8PX69pUWLpT23jv/dfbfP6zTrVvh/VXCj34kffe70pZbhumVK6WRI6W99pI6dJCGDctvO6tWSRdcIHXvLnXtKh1zjFRXV3g98+ZJX/ta2Eb37tL3vietXl1c33vuKe23n/TrXxdeTykQeADKYs2alq/brp3Uq5fUvn3+63TsGNYxa3m/5TJ/vnT//dIZZzTMW7dO2nRT6fzzpaOOyn9bF14o3XuvNGGCNGWK9PHH0tFHh+3la9260Ocnn4RtTJgg3XOPdNFFxfd9xhnS//6vtHZt/vWUjLtX7WPQoEEORGfNGvdLL3WX3CW/beRIv23kyP9M+/PP57WZ9evdr7/efccd3Tfd1P1LX3IfP75h+bvvhs3dc4/78OHunTu77767+2OPNV6e/jj99MK2/de/uh98cGjzhz9suL0rrwztx493r6lx32wz9x493I8/3r2ubsPtvfxymH7yyTD9+OPugweH2gcNcp82rWGdVJv6+jB9223uXbuGdfbYw71LF/dhw9zfeafx63btte7bbBPannqq+09+4t6vX14veYv98pfuAwdmX37eee4HHdT8dj76yL1DB/e//KVh3rx57mbu//hH/vVMmhTWmTevYd748e6dOrkvX15c36tWhe1Mnpx/Pekk1XoLM4UjPGAj9T//I916q3TTTdLMmdLll0vnnCM9/HDjdqNHh+GqV1+V9tlHOukk6dNPwzDivfeGNjNmhOHB3/2usG1ffnkYpps5Mwxv/fa3UpcuYVsLF0oXXxzarV4t/fSnoYaHHgpDqCef3Pw+Xn65dN110iuvhKHLb30rRGk2q1ZJP/+5NHasNHWq9NFH0rnnNiy/665Qx89+Fra5++75Db/tsUcYqs322GOP3OtPmSLV1DTfT3OmTQtH0ocf3jCvb9+wH88/n/92pk4N6/Tt2zDviCPC6zdtWnF9d+wYhqaffjr/ekqlgAECAG3FZ5+FX9SPPSb913+FeTvsIL30Ugip9CGyH/wgnKuRpGuvle64Q5o+XTrgAGnrrcP8bbYJ52UK3fYFF0jHH98wveWWYYixV6/G9X772w3Pd9wxDHntvns4/7Pddtn38+qrpYMPDs+vuCLU/P772ddZuzbUuOuuYfrii8MQ2/r10iabhEAfOVI666yw/PLLpSeflN56K3sNkjRpUu4h2w4dcq//3nuFnZ/MZtGiMPybeq9SevYMywrZTs+ejed17x62nW07hfTdu3e4EKncCDxgIzRzZrjoYcSIxuew1qyR+vdv3HavvRqe9+4d/l28uDTbzveo5ZVXwpHV9OnSsmUNR2nz5uUOvGy1Z1unU6eGsEuts2ZNONLbemtp1izp7LMbr7Pvvs0HXr9+uZc35/PPw/m61uJe+LnMbO0L3U6mvjt3DvtcbgQesBFavz78++CD0vbbN17W9GgjfTr1iym1frHb7tq1+Vo/+ywMlw0fLo0fH44mlywJR4/NXRVYaO1NL3rJtE5LLnLZY49wlJZNv35hWDib7t2lDz8svN+mevUKF4gsWSL16NEwf/Fi6cADC9vOc881nrdkSdh20yO/lvS9bNmGfxyVA4EHbIQGDAhHM++9Jx1ySMu307Fj+Df9Krtitt2x44ZXC86aFX5JXnttGBqVpP/7v5bXXIzddgtDs+lXS770UvPrFTukOXBgOHIu1qBBoa/Jk6VTTgnz6uqkN94IH9PI15Ah0jXXNB5Snjw5vO+DBhXf9+uvS9/4RmH7VgoEHrAR2nzzcH7q4ovDkNKBB4YLUV54IZyrGjUqv+306xeOeB5+OJzn69y5uG337x+GQydPDr/ku3QJR4mdOkk33iidd174BfnjH5fkZSjY978fwm6ffcIR5n33SS++KG21Ve71ih3SPOKI0O/atY2PQmfODEe5S5aE13j69DA/db7vpZek004L510HDw7nSM88U/rhD8ORcrdu0n//dxj6HT48/3oOPzwctZ52mnTDDdLSpWGbZ58tbbFFcX3PnRvOs6Zf3FIuXKUJbKSuvlr6yU+kX/0q/PI67LBw1WXqKCofffqEc2ujR4ehrPPPL27b++8froo8+eQw7PWLX4R/b789fA5twIDQX+rKyOaGNEvtpJNC2F52WQjk118P9bbm+TVJOvLI8MfEo49uOH/gQOnuu8NVkAMHhkfKihXSm2+Gf1N+85tw9HTiidLQoeEq0QcfDBeUpPTvHy7OyaZdu/BHTpcuYRsnnhi2+atfFd/3hAkh7Ir9I6ElzHNdw1thNTU1XlvIvYSAjcHateG6/+uvlySNS34zjRw3Lix//vkw5hSBFSvCRxUGDgxDhptvXv4ajjsuvCUPPti6/dx8s/T3v0tPPNG6/axYEY6+xo7N76MfpbRqlbTzziH0hg5t2TbMbJq7t+hDHAxpAqhan30Wjgq7dZO+/vUwZNaa4bdiRfhIxIgRYWjx3nulBx5o+Dxiazr77HAxx/LlDbcXaw1PPhmuPC132EnhvO/o0S0Pu2IReACq3tKl4YPut97auuFnJj3ySLiA5vPPw9HI+PHhKK+1tWsX7qfZ2o46qrBblZXSLruER6UQeADalNYMv86dpccfL12tqC5ctAKgzUqF3/77h8vnf/CDcFuslSvDjY+BdAQegI0C4YfmEHgANjqEHzLhHB7Qxrikz1cU9v1mbdEmm4SrFotVrgteUP1KEnhmNkLS7yS1k/Rnd7+uyfJOku6QNEjSUkknuvvcUvQNxOaTT6TvfVd65plKV9L6li4t/fYIv3gVHXhm1k7STZIOk1Qn6WUzm+ju6XeGO1PSh+6+k5mdJOl6SScW2zcQo/Xrw9etvPtupStp2wi/+JTiHN5gSXPc/R13Xy3pLknHNmlzrKTbk+f3SDrUrCX3JAeA0uOcXxxKMaTZR9L8tOk6Sftma+Pua81suaRukpbk2vDSpUs1LnU7JSAW7uFL28aOlSQt+uADSdJtt4ZpLZylnXd+U9tuW6kCN37r1kljxoRvd9hll3AEmPqSWLRdpQi8TEdqTW/QmU+b0NBslKRRktSnT5/iKgPaoiaDH+7hSOPZ5xrm5/rONxRnk03Cl8H27Bn+Tb3WhF3bV4rAq5PUN216O0kLsrSpM7P2kraUlPH6K3cfI2mMFG4ePTLXLb2BCNx66zjNni2NHTuy0qVstDbdNNw/c+TIcCf/1avD1+Bw4qX6nJH+ZYUFKkXgvSxpZzPbQdL7kk6SdEqTNhMlnS5pqqTjJf3Tq/lrGoAq065dnBdRrFyZ+4tVi5Er5Dp3bp0+UVlFB15yTu58SY8qfCxhrLvPMLOrJNW6+0RJt0oab2ZzFI7sTiq2XyAWZtIXvyjV11e6kvIyC18Gm/qy01Ig5OJWks/hufskSZOazLsi7flKSSeUoi8gNqlzR506VbaOSujdu/htEHJI4U4rADY6hBwyIfAAbBQIOTSHwAPQZhFyKASBB6BNIeTQUgQegKpHyKEUCDwAVatLF+n++wk5lAaBB6CqHXMMIYfSIPAAVK2uXStdATYm3A4VABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEIWiAs/MtjazyWY2O/l3qyzt1pnZ9OQxsZg+AQBoiWKP8C6T9IS77yzpiWQ6k8/dfe+vRcRYAAAK3UlEQVTkcUyRfQIAULBiA+9YSbcnz2+X9PUitwcAQKsoNvB6uvtCSUr+3SZLu03NrNbMXjCznKFoZqOStrX19fVFlgcAQNC+uQZm9rikXhkWjS6gn+3dfYGZ7Sjpn2b2mru/namhu4+RNEaSampqvIA+AADIqtnAc/fh2ZaZ2Qdmtq27LzSzbSUtzrKNBcm/75jZU5IGSsoYeAAAtIZihzQnSjo9eX66pAeaNjCzrcysU/K8u6ShkmYW2S8AAAUpNvCuk3SYmc2WdFgyLTOrMbM/J212l1RrZq9KelLSde5O4AEAyqrZIc1c3H2ppEMzzK+VdFby/HlJexbTDwAAxeJOKwCAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCgQeACAKBQVeGZ2gpnNMLP1ZlaTo90IM3vTzOaY2WXF9AkAQEsUe4T3uqRvSHomWwMzayfpJklflTRA0slmNqDIfgEAKEj7YlZ29zckycxyNRssaY67v5O0vUvSsZJmFtM3AACFKMc5vD6S5qdN1yXzMjKzUWZWa2a19fX1rV4cACAOzR7hmdnjknplWDTa3R/Io49Mh3+erbG7j5E0RpJqamqytgMAoBDNBp67Dy+yjzpJfdOmt5O0oMhtAgBQkHIMab4saWcz28HMOko6SdLEMvQLAMB/FPuxhOPMrE7SEEkPm9mjyfzeZjZJktx9raTzJT0q6Q1Jf3P3GcWVDQBAYYq9SvM+SfdlmL9A0pFp05MkTSqmLwAAisGdVgAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSDwAABRIPAAAFEg8AAAUSgq8MzsBDObYWbrzawmR7u5ZvaamU03s9pi+gQAoCXaF7n+65K+IelPebQ92N2XFNkfAAAtUlTgufsbkmRmpakGAIBWUq5zeC7pMTObZmajcjU0s1FmVmtmtfX19WUqDwCwsWv2CM/MHpfUK8Oi0e7+QJ79DHX3BWa2jaTJZjbL3Z/J1NDdx0gaI0k1NTWe5/YBAMip2cBz9+HFduLuC5J/F5vZfZIGS8oYeAAAtIZWH9I0s65mtnnquaTDFS52AQCgbIr9WMJxZlYnaYikh83s0WR+bzOblDTrKelZM3tV0kuSHnb3fxTTLwAAhSr2Ks37JN2XYf4CSUcmz9+R9OVi+gEAoFjcaQUAEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBQIPABAFAg8AEAUCDwAQBXP3SteQlZl9IunNStdRhO6SllS6iCKxD9WBfagObX0f2nr9krSru2/ekhXbl7qSEnvT3WsqXURLmVltW65fYh+qBftQHdr6PrT1+qWwDy1dlyFNAEAUCDwAQBSqPfDGVLqAIrX1+iX2oVqwD9Whre9DW69fKmIfqvqiFQAASqXaj/AAACgJAg8AEIWqCjwz+6WZzTKzf5vZfWb2hSztRpjZm2Y2x8wuK3ed2ZjZCWY2w8zWm1nWS3/NbK6ZvWZm04u5xLY1FLAPVfkeSJKZbW1mk81sdvLvVlnarUveg+lmNrHcdWbS3OtqZp3M7O5k+Ytm1r/8VWaXR/0jzaw+7XU/qxJ15mJmY81ssZm9nmW5mdnvk338t5l9pdw15pJH/cPMbHnae3BFuWtsjpn1NbMnzeyN5PfR9zO0Kfx9cPeqeUg6XFL75Pn1kq7P0KadpLcl7Sipo6RXJQ2odO1JbbtL2lXSU5JqcrSbK6l7pett6T5U83uQ1PcLSZclzy/L9HOULPu00rUW+rpK+q6km5PnJ0m6u9J1F1j/SEk3VrrWZvbjQElfkfR6luVHSnpEkknaT9KLla65wPqHSXqo0nU2sw/bSvpK8nxzSW9l+Fkq+H2oqiM8d3/M3dcmky9I2i5Ds8GS5rj7O+6+WtJdko4tV425uPsb7t6W7wyT7z5U7XuQOFbS7cnz2yV9vYK1FCKf1zV93+6RdKiZWRlrzKXafy7y4u7PSFqWo8mxku7w4AVJXzCzbctTXfPyqL/quftCd38lef6JpDck9WnSrOD3oaoCr4lvK6R3U30kzU+brtOGL0S1c0mPmdk0MxtV6WJaoNrfg57uvlAK/3EkbZOl3aZmVmtmL5hZNYRiPq/rf9okfxwul9StLNU1L9+fi28mQ1D3mFnf8pRWUtX+85+PIWb2qpk9YmZ7VLqYXJJh+4GSXmyyqOD3oey3FjOzxyX1yrBotLs/kLQZLWmtpDszbSLDvLJ9tiKf+vMw1N0XmNk2kiab2azkr7KyKME+VPQ9kHLvQwGb2T55H3aU9E8ze83d3y5NhS2Sz+ta8dc+h3xqe1DSBHdfZWbnKhytHtLqlZVWNb8H+XhFUj93/9TMjpR0v6SdK1xTRma2maR7JV3o7h83XZxhlZzvQ9kDz92H51puZqdLOlrSoZ4M1DZRJyn9r8LtJC0oXYW5NVd/nttYkPy72MzuUxgKKlvglWAfKvoeSLn3wcw+MLNt3X1hMsSxOMs2Uu/DO2b2lMJfkZUMvHxe11SbOjNrL2lLVc/wVbP1u/vStMlbFM7VtzUV//kvRnpwuPskM/ujmXV396q6qbSZdVAIuzvd/f8yNCn4faiqIU0zGyHpUknHuPuKLM1elrSzme1gZh0VTtxXxRV2+TCzrma2eeq5woU6Ga+mqmLV/h5MlHR68vx0SRsctZrZVmbWKXneXdJQSTPLVmFm+byu6ft2vKR/ZvnDsBKarb/JOZZjFM7NtDUTJZ2WXCW4n6TlqSH0tsDMeqXO+5rZYIUcWJp7rfJK6rtV0hvu/usszQp/Hyp9NU6Tq27mKIzJTk8eqavRekua1OTqnLcU/hofXem60+o6TuGvjlWSPpD0aNP6Fa5gezV5zKim+vPdh2p+D5Laukl6QtLs5N+tk/k1kv6cPN9f0mvJ+/CapDMrXXe211XSVQp/BErSppL+nvxfeUnSjpWuucD6f5783L8q6UlJu1W65gz7MEHSQklrkv8LZ0o6V9K5yXKTdFOyj68pxxXZVVr/+WnvwQuS9q90zRn24QCF4cl/p+XBkcW+D9xaDAAQhaoa0gQAoLUQeACAKBB4AIAoEHgAgCgQeACAKBB4AIAoEHgAgCj8f+fOeAW3kmqhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac9134898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "new_blank_plot(title='words as discrete symbols')\n",
    "draw_vector2d(one_hot_vec[0], color='blue')\n",
    "draw_vector2d(one_hot_vec[1], color='red')\n",
    "draw_label2d(one_hot_vec[0], processed_positive_review.split()[0], color='blue', coords=True)\n",
    "draw_label2d(one_hot_vec[1], processed_positive_review.split()[1], color='red', coords=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** These 2 vectors are <font color='red'>orthogonal** <br/>\n",
    "** There is no natural notion of <font color='red'> similarity for one-hot vectors!**\n",
    "<h2>  Learn to encode similarity in the vectors themselves !</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solution 2: Representing words by their context\n",
    "* ** Distributional semantics: A word‚Äôs meaning is given by the words that frequently appear close-by **\n",
    "* When a word w appears in a text, its context is the set of wordsthat appear nearby (within a fixed-size window).\n",
    "* Use the many contexts of $w$ to build up a representation of $w$\n",
    "<img src=\"images/Context_representation.PNG\", width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word Vectors/Embeddings</h2> </font> \n",
    "* We will build a dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts.\n",
    "<br/>\n",
    "* **Lower dimensional** -> We consider a word embedding to a D dimensional vector space where D is less than the size of the vocabulary. (in practice it is a linear projection from the embedding space created by one hot encoding and D is no more than 500).\n",
    "<br/>\n",
    "* **‚ÄúSemantic and Syntax‚Äù** -> Word vectors will be allowed to be non-orthogonal. In non-mathematical terms we will preserve the semantic similarity of words by using the direction of the word vectors.\n",
    "\n",
    "<img src=\"images/linear-relationships.svg\", width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word2Vec Efficient high dimensional word embeddings </h2> </font> \n",
    "Idea:\n",
    "\n",
    "‚Ä¢ We have a large corpus of text \n",
    "\n",
    "‚Ä¢ Every word in a fixed vocabulary is represented by a vector\n",
    "\n",
    "‚Ä¢ Go through each position t in the text, which has a center word c and context (‚Äúoutside‚Äù) words o\n",
    "\n",
    "‚Ä¢ Use the similarity of the word vectors for c and o to calculate the probability of o given c (or vice versa)\n",
    "\n",
    "‚Ä¢ Keep adjusting the word vectors to maximize this probability\n",
    "\n",
    "Example\twindows\tand\tprocess\tfor\tcomputing $P(w_{t+j}|w_t)$\n",
    "<img src=\"images/example_context_rep.png\", width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>token</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>...</th>\n",
       "      <th>v_290</th>\n",
       "      <th>v_291</th>\n",
       "      <th>v_292</th>\n",
       "      <th>v_293</th>\n",
       "      <th>v_294</th>\n",
       "      <th>v_295</th>\n",
       "      <th>v_296</th>\n",
       "      <th>v_297</th>\n",
       "      <th>v_298</th>\n",
       "      <th>v_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193359</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>-0.093262</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>-0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>year</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.174805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>one</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.103516</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.095215</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>-0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>would</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>also</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>-0.152344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  token       v_0       v_1       v_2       v_3       v_4  \\\n",
       "0           0   said -0.009094 -0.044189  0.099609 -0.076172 -0.056641   \n",
       "1           1   year  0.061768  0.257812  0.003677  0.145508 -0.037354   \n",
       "2           2    one  0.045654 -0.145508  0.156250  0.166016  0.109863   \n",
       "3           3  would  0.089355  0.129883  0.212891  0.177734 -0.113281   \n",
       "4           4   also  0.053467  0.012024 -0.006500  0.008545  0.016479   \n",
       "\n",
       "        v_5       v_6       v_7    ...        v_290     v_291     v_292  \\\n",
       "0  0.061523  0.255859 -0.158203    ...    -0.193359  0.029907 -0.093262   \n",
       "1 -0.120117  0.188477 -0.154297    ...    -0.031738  0.056396 -0.156250   \n",
       "2  0.007507  0.073730 -0.031006    ...    -0.028931 -0.013000 -0.060303   \n",
       "3 -0.094727  0.091797 -0.029663    ...    -0.267578  0.087891 -0.071289   \n",
       "4  0.183594 -0.070801 -0.059326    ...    -0.071777 -0.114258  0.040039   \n",
       "\n",
       "      v_293     v_294     v_295     v_296     v_297     v_298     v_299  \n",
       "0  0.053711 -0.117676  0.069824  0.105957  0.144531  0.180664 -0.086914  \n",
       "1 -0.146484  0.007874 -0.133789 -0.046631  0.111816  0.072754 -0.174805  \n",
       "2 -0.032715 -0.103516  0.044678 -0.095215 -0.015869  0.006714 -0.001884  \n",
       "3  0.130859  0.061768  0.187500  0.039307 -0.152344  0.005524 -0.100586  \n",
       "4 -0.078125 -0.029541  0.074219  0.054932 -0.001938  0.032227 -0.152344  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pre-trained word 2 vec embeddings\n",
    "import pandas as pd\n",
    "embeddings_vocab = pd.read_csv('data/embeddings_vocab.csv')\n",
    "embeddings_vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<font color='red'> <h2> Do not run this cell! </h2> </font> \n",
    "<font color='red'> <h2> The cell below uses t-SNE to project the word embeddings from 300 d to 2D </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 27989 samples in 6.225s...\n",
      "[t-SNE] Computed neighbors for 27989 samples in 1490.779s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 27989\n",
      "[t-SNE] Computed conditional probabilities for sample 27989 / 27989\n",
      "[t-SNE] Mean sigma: 0.674907\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 110.711159\n",
      "[t-SNE] Error after 300 iterations: 5.337484\n"
     ]
    }
   ],
   "source": [
    "## Project in 2D for visualization purpose\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(embeddings_vocab.loc[:, 'v_0':])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> <h2> Do not run this cell! </h2> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "tsne_embeddings = pd.DataFrame(columns = ['token','v_1','v_2'])\n",
    "tsne_embeddings['token'] = embeddings_vocab['token']\n",
    "tsne_embeddings['v_1'] = tsne_results[:,0]\n",
    "tsne_embeddings['v_2'] = tsne_results[:,1]\n",
    "tsne_embeddings.to_csv('data/tsne_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "colors=['blue','red','green','yellow','brown','orange']\n",
    "def visualize_words_w2v(my_list_of_words):\n",
    "    figure()\n",
    "    for i in range(len(my_list_of_words)):\n",
    "        if my_list_of_words[i] in tsne_embeddings['token'].values:\n",
    "            new_blank_plot(title='words embeddings Word2Vec',xlim=(-3, 3), ylim=(-3, 3))\n",
    "            draw_vector2d(list(tsne_embeddings[tsne_embeddings['token']==my_list_of_words[i]].values[0][1:]), color=colors[i])\n",
    "            draw_label2d(list(tsne_embeddings[tsne_embeddings['token']==my_list_of_words[i]].values[0][1:]), my_list_of_words[i], color=colors[i], coords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_vocab size: (27989, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>...</th>\n",
       "      <th>v_290</th>\n",
       "      <th>v_291</th>\n",
       "      <th>v_292</th>\n",
       "      <th>v_293</th>\n",
       "      <th>v_294</th>\n",
       "      <th>v_295</th>\n",
       "      <th>v_296</th>\n",
       "      <th>v_297</th>\n",
       "      <th>v_298</th>\n",
       "      <th>v_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.099609</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.255859</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193359</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>-0.093262</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>-0.117676</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>0.105957</td>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>-0.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>0.188477</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>0.213867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.174805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>0.157227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.060303</td>\n",
       "      <td>-0.032715</td>\n",
       "      <td>-0.103516</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>-0.095215</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>-0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.212891</td>\n",
       "      <td>0.177734</td>\n",
       "      <td>-0.113281</td>\n",
       "      <td>-0.094727</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.061768</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.039307</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>-0.100586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>also</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.059326</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.029541</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.054932</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>-0.152344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   token       v_0       v_1       v_2       v_3       v_4       v_5  \\\n",
       "0   said -0.009094 -0.044189  0.099609 -0.076172 -0.056641  0.061523   \n",
       "1   year  0.061768  0.257812  0.003677  0.145508 -0.037354 -0.120117   \n",
       "2    one  0.045654 -0.145508  0.156250  0.166016  0.109863  0.007507   \n",
       "3  would  0.089355  0.129883  0.212891  0.177734 -0.113281 -0.094727   \n",
       "4   also  0.053467  0.012024 -0.006500  0.008545  0.016479  0.183594   \n",
       "\n",
       "        v_6       v_7       v_8    ...        v_290     v_291     v_292  \\\n",
       "0  0.255859 -0.158203  0.016602    ...    -0.193359  0.029907 -0.093262   \n",
       "1  0.188477 -0.154297  0.213867    ...    -0.031738  0.056396 -0.156250   \n",
       "2  0.073730 -0.031006  0.157227    ...    -0.028931 -0.013000 -0.060303   \n",
       "3  0.091797 -0.029663  0.027710    ...    -0.267578  0.087891 -0.071289   \n",
       "4 -0.070801 -0.059326  0.014221    ...    -0.071777 -0.114258  0.040039   \n",
       "\n",
       "      v_293     v_294     v_295     v_296     v_297     v_298     v_299  \n",
       "0  0.053711 -0.117676  0.069824  0.105957  0.144531  0.180664 -0.086914  \n",
       "1 -0.146484  0.007874 -0.133789 -0.046631  0.111816  0.072754 -0.174805  \n",
       "2 -0.032715 -0.103516  0.044678 -0.095215 -0.015869  0.006714 -0.001884  \n",
       "3  0.130859  0.061768  0.187500  0.039307 -0.152344  0.005524 -0.100586  \n",
       "4 -0.078125 -0.029541  0.074219  0.054932 -0.001938  0.032227 -0.152344  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the embeddings of the reviews corpus\n",
    "embeddings_vocab = pd.read_csv('data/embeddings_vocab.csv', index_col=0)\n",
    "print('embeddings_vocab size: {}'.format(embeddings_vocab.shape))\n",
    "embeddings_vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ac6ff57f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the 2D embeddings \n",
    "tsne_embeddings = pd.read_csv('data/tsne_embeddings.csv', index_col=0)\n",
    "# visualize a list of words \n",
    "visualize_words_w2v(processed_positive_review.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> NLP Pipeline </h2> </font> \n",
    "<img src=\"images/nlp_pipeline_3.png\", width=1100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Word2Vec Efficient high dimensional word embeddings </h2> </font> \n",
    "* Take average of the word2vecs of its words (used in first example SVM)\n",
    "* Concatenate the word embeddings to form the sentence (used in second example CNN)\n",
    "* Another approach: Paragraph vector (2014, Quoc Le, Mikolov)\n",
    "  * Extend word2vec to text level\n",
    "  * Also two models: add paragraph vector as the input\n",
    "<img src=\"images/sentence_embed.png\", width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing good say scanner image quality poor sl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recieved skin birthday go sansa e excellent fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resolved issues lock pathetically poor gratefu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work yes well nearly hoped tiny reviews stated...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leaving vacation couple days could find batter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  nothing good say scanner image quality poor sl...          0\n",
       "1  recieved skin birthday go sansa e excellent fi...          1\n",
       "2  resolved issues lock pathetically poor gratefu...          0\n",
       "3  work yes well nearly hoped tiny reviews stated...          0\n",
       "4  leaving vacation couple days could find batter...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the amazon reviews dataset\n",
    "data = pd.read_csv('data/amazon_data_10k.csv', index_col=0)\n",
    "# pre_process the reviews dataset\n",
    "data['reviews'] = data['reviews'].apply(lambda x: pre_process(x))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>...</th>\n",
       "      <th>v_291</th>\n",
       "      <th>v_292</th>\n",
       "      <th>v_293</th>\n",
       "      <th>v_294</th>\n",
       "      <th>v_295</th>\n",
       "      <th>v_296</th>\n",
       "      <th>v_297</th>\n",
       "      <th>v_298</th>\n",
       "      <th>v_299</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able adjust see returning</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>0.157257</td>\n",
       "      <td>-0.144531</td>\n",
       "      <td>0.138062</td>\n",
       "      <td>-0.192871</td>\n",
       "      <td>-0.048706</td>\n",
       "      <td>0.055237</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126587</td>\n",
       "      <td>-0.040558</td>\n",
       "      <td>-0.037659</td>\n",
       "      <td>-0.080322</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.132107</td>\n",
       "      <td>-0.121521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able burn six cds failure rate</td>\n",
       "      <td>0.123006</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.208903</td>\n",
       "      <td>-0.009644</td>\n",
       "      <td>-0.065979</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>-0.048177</td>\n",
       "      <td>0.126119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>-0.106160</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>-0.084310</td>\n",
       "      <td>0.036051</td>\n",
       "      <td>-0.075643</td>\n",
       "      <td>-0.018814</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>able burn whole thing toast pioneer dvrd verif...</td>\n",
       "      <td>0.066411</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.033649</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>-0.066444</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.100611</td>\n",
       "      <td>-0.106558</td>\n",
       "      <td>0.051306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051652</td>\n",
       "      <td>-0.137921</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>-0.026442</td>\n",
       "      <td>0.019259</td>\n",
       "      <td>-0.046023</td>\n",
       "      <td>-0.059559</td>\n",
       "      <td>0.020724</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>able collapse small certainly moderately easy ...</td>\n",
       "      <td>0.053085</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>-0.025433</td>\n",
       "      <td>0.097164</td>\n",
       "      <td>-0.119775</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.025415</td>\n",
       "      <td>-0.034370</td>\n",
       "      <td>0.111130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098162</td>\n",
       "      <td>-0.056672</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.043048</td>\n",
       "      <td>-0.044175</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>able connect mac pc wireless keyboard mouse vi...</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>-0.045933</td>\n",
       "      <td>0.111139</td>\n",
       "      <td>-0.089738</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.025286</td>\n",
       "      <td>-0.031473</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>-0.074852</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>-0.032774</td>\n",
       "      <td>0.024424</td>\n",
       "      <td>-0.074364</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>able find much less amazon local office supply...</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.033186</td>\n",
       "      <td>-0.067943</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>-0.030667</td>\n",
       "      <td>0.059219</td>\n",
       "      <td>-0.016188</td>\n",
       "      <td>-0.026700</td>\n",
       "      <td>0.091071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>-0.084671</td>\n",
       "      <td>0.074480</td>\n",
       "      <td>0.060994</td>\n",
       "      <td>0.045754</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>-0.031968</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>-0.031531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>able find sony meg cdr discs worked flawlesly ...</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>0.080623</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>0.069319</td>\n",
       "      <td>-0.054742</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>-0.038602</td>\n",
       "      <td>0.098650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096301</td>\n",
       "      <td>-0.093292</td>\n",
       "      <td>0.024289</td>\n",
       "      <td>-0.014452</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.030175</td>\n",
       "      <td>-0.051252</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>-0.043039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>able get exactly needed amazon site included d...</td>\n",
       "      <td>0.039483</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.073076</td>\n",
       "      <td>-0.047072</td>\n",
       "      <td>-0.033643</td>\n",
       "      <td>0.121501</td>\n",
       "      <td>-0.050765</td>\n",
       "      <td>0.059246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042418</td>\n",
       "      <td>-0.058828</td>\n",
       "      <td>0.031896</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>-0.041686</td>\n",
       "      <td>-0.012453</td>\n",
       "      <td>-0.050984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able get keyboard work infared sensor seems pr...</td>\n",
       "      <td>0.081968</td>\n",
       "      <td>-0.021428</td>\n",
       "      <td>-0.071152</td>\n",
       "      <td>0.068101</td>\n",
       "      <td>-0.107983</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>0.085796</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.058860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068588</td>\n",
       "      <td>-0.047434</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>-0.054970</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>-0.048201</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>able get online using dialup modem trendnets c...</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>0.027277</td>\n",
       "      <td>-0.028167</td>\n",
       "      <td>0.068418</td>\n",
       "      <td>-0.073675</td>\n",
       "      <td>0.044399</td>\n",
       "      <td>0.040515</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>-0.081374</td>\n",
       "      <td>0.018595</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>-0.017888</td>\n",
       "      <td>0.026420</td>\n",
       "      <td>-0.028648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>able get strong signal every corner house back...</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.054987</td>\n",
       "      <td>-0.012636</td>\n",
       "      <td>0.082138</td>\n",
       "      <td>-0.020368</td>\n",
       "      <td>-0.036176</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>-0.079625</td>\n",
       "      <td>0.121386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037979</td>\n",
       "      <td>-0.098474</td>\n",
       "      <td>-0.012189</td>\n",
       "      <td>-0.045479</td>\n",
       "      <td>-0.076596</td>\n",
       "      <td>-0.014171</td>\n",
       "      <td>-0.042561</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>-0.008649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>able get sub amazon skeptical first due price ...</td>\n",
       "      <td>0.028022</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>-0.008753</td>\n",
       "      <td>0.058633</td>\n",
       "      <td>-0.023907</td>\n",
       "      <td>-0.026045</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>-0.014955</td>\n",
       "      <td>0.079577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>-0.088116</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>-0.005171</td>\n",
       "      <td>-0.006553</td>\n",
       "      <td>-0.039348</td>\n",
       "      <td>-0.086576</td>\n",
       "      <td>0.059854</td>\n",
       "      <td>-0.057777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>able get work windows worked fine vista proble...</td>\n",
       "      <td>0.076322</td>\n",
       "      <td>0.022173</td>\n",
       "      <td>-0.029696</td>\n",
       "      <td>0.090036</td>\n",
       "      <td>-0.042757</td>\n",
       "      <td>0.058603</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>-0.002732</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118756</td>\n",
       "      <td>-0.092172</td>\n",
       "      <td>-0.023658</td>\n",
       "      <td>-0.040213</td>\n",
       "      <td>0.093055</td>\n",
       "      <td>0.066826</td>\n",
       "      <td>-0.035722</td>\n",
       "      <td>0.049307</td>\n",
       "      <td>-0.027960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>able get work windows xp worked windows starts...</td>\n",
       "      <td>0.028060</td>\n",
       "      <td>0.015791</td>\n",
       "      <td>-0.033022</td>\n",
       "      <td>0.055564</td>\n",
       "      <td>-0.075318</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.043374</td>\n",
       "      <td>-0.050327</td>\n",
       "      <td>0.125891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>-0.058823</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-0.009779</td>\n",
       "      <td>-0.040835</td>\n",
       "      <td>-0.061705</td>\n",
       "      <td>-0.017015</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>able give full test yet aware firewire port li...</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>-0.030205</td>\n",
       "      <td>-0.013144</td>\n",
       "      <td>0.063639</td>\n",
       "      <td>-0.093198</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>-0.045786</td>\n",
       "      <td>0.121369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104656</td>\n",
       "      <td>-0.041385</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.021921</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.028833</td>\n",
       "      <td>-0.070976</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>-0.012090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>able hook two computers router configs access ...</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>-0.078208</td>\n",
       "      <td>-0.010939</td>\n",
       "      <td>0.068421</td>\n",
       "      <td>-0.094533</td>\n",
       "      <td>0.044288</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>-0.030450</td>\n",
       "      <td>0.117626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083125</td>\n",
       "      <td>-0.037606</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>-0.044660</td>\n",
       "      <td>-0.072666</td>\n",
       "      <td>-0.032037</td>\n",
       "      <td>-0.063754</td>\n",
       "      <td>-0.002800</td>\n",
       "      <td>-0.030479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>able install couple screwdrivers watching yout...</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>-0.022040</td>\n",
       "      <td>0.121102</td>\n",
       "      <td>-0.128143</td>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.033583</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080160</td>\n",
       "      <td>-0.105442</td>\n",
       "      <td>-0.028581</td>\n",
       "      <td>-0.022569</td>\n",
       "      <td>-0.087402</td>\n",
       "      <td>0.099598</td>\n",
       "      <td>-0.030440</td>\n",
       "      <td>-0.010078</td>\n",
       "      <td>-0.027364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>able install modem old dell machine windows se...</td>\n",
       "      <td>0.081597</td>\n",
       "      <td>-0.000354</td>\n",
       "      <td>-0.011024</td>\n",
       "      <td>0.082934</td>\n",
       "      <td>-0.067627</td>\n",
       "      <td>0.071526</td>\n",
       "      <td>0.039078</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>0.128755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093194</td>\n",
       "      <td>-0.043064</td>\n",
       "      <td>-0.007117</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.005039</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>-0.042482</td>\n",
       "      <td>-0.020845</td>\n",
       "      <td>-0.066370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>able install wireless setup router currently u...</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-0.052711</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>-0.068884</td>\n",
       "      <td>0.070465</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.030472</td>\n",
       "      <td>0.146492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>-0.053675</td>\n",
       "      <td>-0.007717</td>\n",
       "      <td>-0.049055</td>\n",
       "      <td>0.026619</td>\n",
       "      <td>0.016911</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>-0.004809</td>\n",
       "      <td>-0.026752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>able mount lcd tv wall giving room desk great ...</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.079978</td>\n",
       "      <td>-0.047935</td>\n",
       "      <td>0.091465</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>-0.014923</td>\n",
       "      <td>0.081959</td>\n",
       "      <td>-0.073714</td>\n",
       "      <td>0.210249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140392</td>\n",
       "      <td>-0.070002</td>\n",
       "      <td>-0.012031</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>-0.071578</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>-0.028040</td>\n",
       "      <td>-0.064819</td>\n",
       "      <td>-0.072766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>able purchase modem less regular price im plea...</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>-0.066195</td>\n",
       "      <td>0.100964</td>\n",
       "      <td>-0.047338</td>\n",
       "      <td>0.024818</td>\n",
       "      <td>0.045089</td>\n",
       "      <td>-0.056210</td>\n",
       "      <td>0.088492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098445</td>\n",
       "      <td>-0.075636</td>\n",
       "      <td>0.078938</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.035747</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>-0.035720</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>-0.023923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>able receive stations advertismentsi get good ...</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.010725</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.080635</td>\n",
       "      <td>-0.095427</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>0.014280</td>\n",
       "      <td>-0.010490</td>\n",
       "      <td>0.131360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035467</td>\n",
       "      <td>-0.071520</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.031680</td>\n",
       "      <td>-0.066958</td>\n",
       "      <td>-0.043677</td>\n",
       "      <td>-0.092289</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>-0.051235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>able remove laptop disk drive put device put n...</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.045984</td>\n",
       "      <td>-0.021227</td>\n",
       "      <td>0.047969</td>\n",
       "      <td>-0.132310</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.101305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087597</td>\n",
       "      <td>-0.040086</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>-0.015471</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>-0.080407</td>\n",
       "      <td>-0.027701</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>able use computer home ended giving away frien...</td>\n",
       "      <td>0.056876</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.048196</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.048983</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.069791</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124878</td>\n",
       "      <td>-0.120073</td>\n",
       "      <td>-0.022411</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>-0.065211</td>\n",
       "      <td>-0.033089</td>\n",
       "      <td>-0.024081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>absolute awesome shelf cd player smaller cheap...</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.164429</td>\n",
       "      <td>-0.018637</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>0.038505</td>\n",
       "      <td>-0.064277</td>\n",
       "      <td>0.100774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119902</td>\n",
       "      <td>-0.124180</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>-0.031176</td>\n",
       "      <td>-0.046389</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>-0.043967</td>\n",
       "      <td>-0.005890</td>\n",
       "      <td>-0.003734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>absolute best mp player ever purchased best pi...</td>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.084023</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.082522</td>\n",
       "      <td>-0.108492</td>\n",
       "      <td>0.103766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078985</td>\n",
       "      <td>-0.094000</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>-0.048680</td>\n",
       "      <td>-0.049529</td>\n",
       "      <td>-0.011748</td>\n",
       "      <td>-0.073848</td>\n",
       "      <td>-0.005879</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>absolute garbage chose product reasonable seem...</td>\n",
       "      <td>0.014053</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.061349</td>\n",
       "      <td>-0.098677</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>-0.097591</td>\n",
       "      <td>0.079424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>-0.105010</td>\n",
       "      <td>0.062230</td>\n",
       "      <td>-0.022301</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>0.020740</td>\n",
       "      <td>-0.020040</td>\n",
       "      <td>-0.016801</td>\n",
       "      <td>-0.023660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>absolute junk terrible video quality best buy ...</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>0.085245</td>\n",
       "      <td>0.160323</td>\n",
       "      <td>-0.048871</td>\n",
       "      <td>0.075696</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>-0.070930</td>\n",
       "      <td>0.075579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129371</td>\n",
       "      <td>-0.108714</td>\n",
       "      <td>0.020185</td>\n",
       "      <td>-0.049255</td>\n",
       "      <td>0.026590</td>\n",
       "      <td>-0.011834</td>\n",
       "      <td>-0.073357</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>-0.067197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>absolute piece junk buy usually high tolerance...</td>\n",
       "      <td>0.032214</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.131553</td>\n",
       "      <td>-0.061199</td>\n",
       "      <td>0.047167</td>\n",
       "      <td>0.036140</td>\n",
       "      <td>-0.089689</td>\n",
       "      <td>0.103026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044173</td>\n",
       "      <td>-0.100709</td>\n",
       "      <td>0.063453</td>\n",
       "      <td>-0.036738</td>\n",
       "      <td>-0.026992</td>\n",
       "      <td>-0.022626</td>\n",
       "      <td>-0.046516</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.024378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>absolute worst batteries ever dont hold charge...</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>-0.006421</td>\n",
       "      <td>0.162671</td>\n",
       "      <td>0.061792</td>\n",
       "      <td>-0.088306</td>\n",
       "      <td>0.050275</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>-0.087463</td>\n",
       "      <td>0.186609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136401</td>\n",
       "      <td>-0.130310</td>\n",
       "      <td>0.098193</td>\n",
       "      <td>-0.103418</td>\n",
       "      <td>-0.080054</td>\n",
       "      <td>-0.167889</td>\n",
       "      <td>-0.036841</td>\n",
       "      <td>-0.032014</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34767</th>\n",
       "      <td>z listed compatible camera printer dock batter...</td>\n",
       "      <td>0.040156</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.067646</td>\n",
       "      <td>-0.087794</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>0.051457</td>\n",
       "      <td>-0.028618</td>\n",
       "      <td>0.120065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071538</td>\n",
       "      <td>-0.094381</td>\n",
       "      <td>0.035824</td>\n",
       "      <td>-0.005061</td>\n",
       "      <td>-0.004824</td>\n",
       "      <td>-0.021120</td>\n",
       "      <td>-0.046655</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>-0.021604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34768</th>\n",
       "      <td>zaurus sharp pda stucks trying read sandisk sd...</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>0.045864</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.137081</td>\n",
       "      <td>-0.115182</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>-0.003676</td>\n",
       "      <td>-0.116390</td>\n",
       "      <td>0.104632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032445</td>\n",
       "      <td>-0.058027</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>-0.102332</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>-0.100739</td>\n",
       "      <td>-0.045509</td>\n",
       "      <td>0.065447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34769</th>\n",
       "      <td>zaurus sl network engineers dream work cisco r...</td>\n",
       "      <td>0.044555</td>\n",
       "      <td>0.056315</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>0.126345</td>\n",
       "      <td>-0.075515</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.028190</td>\n",
       "      <td>0.068242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044999</td>\n",
       "      <td>-0.072095</td>\n",
       "      <td>0.039203</td>\n",
       "      <td>-0.031009</td>\n",
       "      <td>-0.033953</td>\n",
       "      <td>-0.006565</td>\n",
       "      <td>-0.056584</td>\n",
       "      <td>-0.071555</td>\n",
       "      <td>-0.006239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34770</th>\n",
       "      <td>zeiss quality performance legendary confidence...</td>\n",
       "      <td>0.018233</td>\n",
       "      <td>0.034265</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>-0.065233</td>\n",
       "      <td>-0.019677</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>-0.071700</td>\n",
       "      <td>0.098337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>-0.070269</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.034080</td>\n",
       "      <td>-0.011732</td>\n",
       "      <td>-0.035811</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>-0.048554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34771</th>\n",
       "      <td>zen great couple hours use get use controls us...</td>\n",
       "      <td>0.064642</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>-0.046653</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>-0.041171</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>-0.064387</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101962</td>\n",
       "      <td>-0.070512</td>\n",
       "      <td>-0.016635</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>-0.010347</td>\n",
       "      <td>-0.081476</td>\n",
       "      <td>-0.008478</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34772</th>\n",
       "      <td>zen micro given present makes harder first thi...</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.090580</td>\n",
       "      <td>-0.064023</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.075535</td>\n",
       "      <td>-0.049143</td>\n",
       "      <td>0.092858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077107</td>\n",
       "      <td>-0.064206</td>\n",
       "      <td>0.033620</td>\n",
       "      <td>-0.017860</td>\n",
       "      <td>-0.012943</td>\n",
       "      <td>-0.019096</td>\n",
       "      <td>-0.040716</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>-0.007850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34773</th>\n",
       "      <td>zen micro mostly pleased started freezing died...</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>-0.049758</td>\n",
       "      <td>0.097137</td>\n",
       "      <td>-0.010087</td>\n",
       "      <td>0.034071</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>-0.094139</td>\n",
       "      <td>0.080655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056744</td>\n",
       "      <td>-0.082675</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.014679</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34774</th>\n",
       "      <td>zen stone left pocket washed itstill workeddid...</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>-0.019354</td>\n",
       "      <td>0.073366</td>\n",
       "      <td>-0.040090</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.056303</td>\n",
       "      <td>-0.060222</td>\n",
       "      <td>0.122628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087784</td>\n",
       "      <td>-0.111983</td>\n",
       "      <td>0.029608</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.009319</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.061617</td>\n",
       "      <td>-0.013711</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>zennxs replaceable battery deciding factor pur...</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.019773</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.075754</td>\n",
       "      <td>-0.057659</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.072103</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>0.122282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091741</td>\n",
       "      <td>-0.083823</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>-0.011846</td>\n",
       "      <td>-0.016748</td>\n",
       "      <td>-0.010047</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34776</th>\n",
       "      <td>zero stars option jam would truly deserve nega...</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>0.175729</td>\n",
       "      <td>-0.106036</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.059278</td>\n",
       "      <td>-0.115252</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081569</td>\n",
       "      <td>-0.083653</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>-0.068146</td>\n",
       "      <td>-0.022243</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>-0.065376</td>\n",
       "      <td>-0.039999</td>\n",
       "      <td>0.019741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34777</th>\n",
       "      <td>zero stars rating first time display bright le...</td>\n",
       "      <td>0.077651</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.014566</td>\n",
       "      <td>0.113055</td>\n",
       "      <td>-0.047736</td>\n",
       "      <td>-0.010160</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>-0.085002</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096181</td>\n",
       "      <td>-0.094916</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.042887</td>\n",
       "      <td>-0.006099</td>\n",
       "      <td>-0.055725</td>\n",
       "      <td>-0.002411</td>\n",
       "      <td>-0.009177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34778</th>\n",
       "      <td>zhdtv excellent settop antenna long live relat...</td>\n",
       "      <td>-0.038285</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>-0.005850</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>-0.065312</td>\n",
       "      <td>-0.023386</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>-0.050885</td>\n",
       "      <td>0.092969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>-0.094226</td>\n",
       "      <td>-0.006702</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.026966</td>\n",
       "      <td>-0.032470</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>-0.020711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>ziikanonymousbellavistasfoygnidisclaimer im ce...</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>-0.076296</td>\n",
       "      <td>0.015354</td>\n",
       "      <td>0.060406</td>\n",
       "      <td>-0.056730</td>\n",
       "      <td>0.091036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>-0.054450</td>\n",
       "      <td>0.032823</td>\n",
       "      <td>-0.035525</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.040174</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.013464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34780</th>\n",
       "      <td>zing bags wonderfulgreat protection cameras vi...</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.031960</td>\n",
       "      <td>0.043466</td>\n",
       "      <td>-0.104222</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.071554</td>\n",
       "      <td>-0.031226</td>\n",
       "      <td>0.082872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011369</td>\n",
       "      <td>-0.002645</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.009766</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>-0.009155</td>\n",
       "      <td>-0.105594</td>\n",
       "      <td>-0.023554</td>\n",
       "      <td>-0.089084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34781</th>\n",
       "      <td>zip drive worked fine ceased function returned...</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>-0.038865</td>\n",
       "      <td>0.061556</td>\n",
       "      <td>-0.092369</td>\n",
       "      <td>-0.006621</td>\n",
       "      <td>0.026746</td>\n",
       "      <td>-0.072546</td>\n",
       "      <td>0.077394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054107</td>\n",
       "      <td>-0.095642</td>\n",
       "      <td>0.064771</td>\n",
       "      <td>-0.002058</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>-0.021227</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34782</th>\n",
       "      <td>zipper broken within one day hook broken withi...</td>\n",
       "      <td>-0.061920</td>\n",
       "      <td>-0.012390</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>-0.032990</td>\n",
       "      <td>-0.040329</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>-0.082550</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050056</td>\n",
       "      <td>-0.096527</td>\n",
       "      <td>-0.091064</td>\n",
       "      <td>-0.042023</td>\n",
       "      <td>-0.045837</td>\n",
       "      <td>-0.102982</td>\n",
       "      <td>-0.042084</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>-0.019782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34783</th>\n",
       "      <td>zipper front big pocket bind time time great b...</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.058871</td>\n",
       "      <td>-0.032153</td>\n",
       "      <td>0.081862</td>\n",
       "      <td>-0.095413</td>\n",
       "      <td>-0.024264</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>-0.022748</td>\n",
       "      <td>0.051726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>-0.079164</td>\n",
       "      <td>-0.039678</td>\n",
       "      <td>-0.017563</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>-0.011913</td>\n",
       "      <td>-0.037494</td>\n",
       "      <td>-0.025953</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34784</th>\n",
       "      <td>zipper made poor quality split first time open...</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.117831</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.027219</td>\n",
       "      <td>-0.016163</td>\n",
       "      <td>-0.093073</td>\n",
       "      <td>-0.053855</td>\n",
       "      <td>-0.068112</td>\n",
       "      <td>0.144487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.157515</td>\n",
       "      <td>0.020819</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>-0.080202</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>-0.036249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34785</th>\n",
       "      <td>zipper pretty crappy cheap sometimes unthreads...</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.051507</td>\n",
       "      <td>-0.013937</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>-0.131863</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.057352</td>\n",
       "      <td>-0.006310</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094746</td>\n",
       "      <td>-0.122875</td>\n",
       "      <td>0.071018</td>\n",
       "      <td>-0.083595</td>\n",
       "      <td>0.056171</td>\n",
       "      <td>0.057771</td>\n",
       "      <td>-0.024498</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34786</th>\n",
       "      <td>zire great palm love great battery life high r...</td>\n",
       "      <td>-0.010957</td>\n",
       "      <td>0.048209</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>0.043668</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>0.087128</td>\n",
       "      <td>-0.045872</td>\n",
       "      <td>0.056674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127252</td>\n",
       "      <td>-0.122766</td>\n",
       "      <td>-0.025705</td>\n",
       "      <td>-0.072832</td>\n",
       "      <td>-0.012993</td>\n",
       "      <td>-0.066641</td>\n",
       "      <td>-0.125533</td>\n",
       "      <td>-0.076284</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>zoe dvxl met exceeded every expectation little...</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.031536</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.057929</td>\n",
       "      <td>-0.090697</td>\n",
       "      <td>-0.004489</td>\n",
       "      <td>0.069613</td>\n",
       "      <td>-0.080835</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065187</td>\n",
       "      <td>-0.071268</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>-0.028572</td>\n",
       "      <td>-0.029418</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>-0.050574</td>\n",
       "      <td>-0.007882</td>\n",
       "      <td>-0.019224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>zune car kit works great long cord player does...</td>\n",
       "      <td>0.028711</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>-0.110095</td>\n",
       "      <td>0.057013</td>\n",
       "      <td>-0.008765</td>\n",
       "      <td>0.054980</td>\n",
       "      <td>0.050433</td>\n",
       "      <td>-0.062280</td>\n",
       "      <td>0.152319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181738</td>\n",
       "      <td>-0.092200</td>\n",
       "      <td>-0.040613</td>\n",
       "      <td>-0.044055</td>\n",
       "      <td>-0.082556</td>\n",
       "      <td>-0.066479</td>\n",
       "      <td>-0.021967</td>\n",
       "      <td>-0.048391</td>\n",
       "      <td>-0.032843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>zune gb digital media player browni bought g z...</td>\n",
       "      <td>0.047650</td>\n",
       "      <td>-0.007008</td>\n",
       "      <td>-0.035047</td>\n",
       "      <td>0.132695</td>\n",
       "      <td>-0.014673</td>\n",
       "      <td>-0.027512</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>-0.077223</td>\n",
       "      <td>0.054590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072247</td>\n",
       "      <td>-0.136762</td>\n",
       "      <td>-0.063020</td>\n",
       "      <td>-0.014724</td>\n",
       "      <td>-0.018133</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.119292</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>-0.023275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>zune going ever kill ipod certainly mean zune ...</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.008538</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.094696</td>\n",
       "      <td>-0.067215</td>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.061460</td>\n",
       "      <td>-0.064959</td>\n",
       "      <td>0.086824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071584</td>\n",
       "      <td>-0.086563</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>-0.020138</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>-0.062509</td>\n",
       "      <td>-0.015372</td>\n",
       "      <td>-0.004787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>zune great product standard wifi separates pac...</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>-0.025463</td>\n",
       "      <td>0.086248</td>\n",
       "      <td>-0.025021</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>-0.052218</td>\n",
       "      <td>0.097845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096530</td>\n",
       "      <td>-0.105378</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>-0.031386</td>\n",
       "      <td>-0.078421</td>\n",
       "      <td>-0.043864</td>\n",
       "      <td>-0.014908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>zune hd didnt workwith old docking station lis...</td>\n",
       "      <td>-0.139160</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>-0.049247</td>\n",
       "      <td>-0.058123</td>\n",
       "      <td>-0.047137</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>-0.059256</td>\n",
       "      <td>-0.023455</td>\n",
       "      <td>0.175886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154576</td>\n",
       "      <td>-0.075631</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0.125083</td>\n",
       "      <td>-0.013323</td>\n",
       "      <td>-0.136326</td>\n",
       "      <td>-0.092215</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>0.023525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34793</th>\n",
       "      <td>zune mp player great car packed big rip dollar...</td>\n",
       "      <td>0.054129</td>\n",
       "      <td>-0.008754</td>\n",
       "      <td>-0.023944</td>\n",
       "      <td>0.094769</td>\n",
       "      <td>-0.090864</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.138644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092615</td>\n",
       "      <td>-0.086169</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>-0.031981</td>\n",
       "      <td>-0.012948</td>\n",
       "      <td>-0.028467</td>\n",
       "      <td>-0.075935</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>-0.021138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>zune must sound great small unit plug power pl...</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.068935</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>-0.089518</td>\n",
       "      <td>-0.049292</td>\n",
       "      <td>0.081873</td>\n",
       "      <td>-0.107031</td>\n",
       "      <td>0.126619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092957</td>\n",
       "      <td>-0.111749</td>\n",
       "      <td>-0.031160</td>\n",
       "      <td>-0.049593</td>\n",
       "      <td>-0.033134</td>\n",
       "      <td>-0.023336</td>\n",
       "      <td>-0.040609</td>\n",
       "      <td>-0.079118</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34795</th>\n",
       "      <td>zune vs ipod ipod wins ipod gb evertying need ...</td>\n",
       "      <td>-0.039280</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.112244</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>0.071924</td>\n",
       "      <td>-0.004925</td>\n",
       "      <td>-0.054319</td>\n",
       "      <td>0.054321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077744</td>\n",
       "      <td>-0.079247</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>-0.023064</td>\n",
       "      <td>-0.034286</td>\n",
       "      <td>-0.085489</td>\n",
       "      <td>-0.062325</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34796</th>\n",
       "      <td>zvm awesome great battery life awesome picture...</td>\n",
       "      <td>0.039355</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>-0.018950</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>-0.079338</td>\n",
       "      <td>0.108608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>-0.112941</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>-0.021951</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>-0.091358</td>\n",
       "      <td>-0.019241</td>\n",
       "      <td>-0.021855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34797 rows √ó 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews       v_0       v_1  \\\n",
       "0                              able adjust see returning -0.025772  0.157257   \n",
       "1                         able burn six cds failure rate  0.123006  0.027913   \n",
       "2      able burn whole thing toast pioneer dvrd verif...  0.066411  0.015935   \n",
       "3      able collapse small certainly moderately easy ...  0.053085  0.028626   \n",
       "4      able connect mac pc wireless keyboard mouse vi...  0.024727  0.009866   \n",
       "5      able find much less amazon local office supply...  0.001785  0.033186   \n",
       "6      able find sony meg cdr discs worked flawlesly ...  0.034639  0.080623   \n",
       "7      able get exactly needed amazon site included d...  0.039483  0.053695   \n",
       "8      able get keyboard work infared sensor seems pr...  0.081968 -0.021428   \n",
       "9      able get online using dialup modem trendnets c...  0.029805  0.027277   \n",
       "10     able get strong signal every corner house back...  0.004255  0.054987   \n",
       "11     able get sub amazon skeptical first due price ...  0.028022  0.007134   \n",
       "12     able get work windows worked fine vista proble...  0.076322  0.022173   \n",
       "13     able get work windows xp worked windows starts...  0.028060  0.015791   \n",
       "14     able give full test yet aware firewire port li...  0.025620 -0.030205   \n",
       "15     able hook two computers router configs access ...  0.017356 -0.078208   \n",
       "16     able install couple screwdrivers watching yout...  0.013455  0.026872   \n",
       "17     able install modem old dell machine windows se...  0.081597 -0.000354   \n",
       "18     able install wireless setup router currently u...  0.013294  0.002002   \n",
       "19     able mount lcd tv wall giving room desk great ... -0.005205  0.079978   \n",
       "20     able purchase modem less regular price im plea...  0.011792  0.000862   \n",
       "21     able receive stations advertismentsi get good ...  0.006165 -0.010725   \n",
       "22     able remove laptop disk drive put device put n...  0.013543  0.045984   \n",
       "23     able use computer home ended giving away frien...  0.056876 -0.000122   \n",
       "24     absolute awesome shelf cd player smaller cheap... -0.003033  0.011801   \n",
       "25     absolute best mp player ever purchased best pi...  0.024393  0.048828   \n",
       "26     absolute garbage chose product reasonable seem...  0.014053  0.048072   \n",
       "27     absolute junk terrible video quality best buy ...  0.042755  0.051783   \n",
       "28     absolute piece junk buy usually high tolerance...  0.032214  0.011528   \n",
       "29     absolute worst batteries ever dont hold charge...  0.023389 -0.006421   \n",
       "...                                                  ...       ...       ...   \n",
       "34767  z listed compatible camera printer dock batter...  0.040156  0.018184   \n",
       "34768  zaurus sharp pda stucks trying read sandisk sd...  0.024580  0.045864   \n",
       "34769  zaurus sl network engineers dream work cisco r...  0.044555  0.056315   \n",
       "34770  zeiss quality performance legendary confidence...  0.018233  0.034265   \n",
       "34771  zen great couple hours use get use controls us...  0.064642  0.023252   \n",
       "34772  zen micro given present makes harder first thi...  0.023480  0.019767   \n",
       "34773  zen micro mostly pleased started freezing died...  0.011611  0.057911   \n",
       "34774  zen stone left pocket washed itstill workeddid...  0.061336  0.064711   \n",
       "34775  zennxs replaceable battery deciding factor pur...  0.019350  0.019773   \n",
       "34776  zero stars option jam would truly deserve nega...  0.001317  0.046927   \n",
       "34777  zero stars rating first time display bright le...  0.077651  0.014578   \n",
       "34778  zhdtv excellent settop antenna long live relat... -0.038285  0.014002   \n",
       "34779  ziikanonymousbellavistasfoygnidisclaimer im ce...  0.019937  0.023931   \n",
       "34780  zing bags wonderfulgreat protection cameras vi...  0.001241  0.010117   \n",
       "34781  zip drive worked fine ceased function returned...  0.007543  0.035672   \n",
       "34782  zipper broken within one day hook broken withi... -0.061920 -0.012390   \n",
       "34783  zipper front big pocket bind time time great b...  0.065768  0.058871   \n",
       "34784  zipper made poor quality split first time open...  0.003424  0.117831   \n",
       "34785  zipper pretty crappy cheap sometimes unthreads...  0.052326  0.051507   \n",
       "34786  zire great palm love great battery life high r... -0.010957  0.048209   \n",
       "34787  zoe dvxl met exceeded every expectation little...  0.028796  0.031536   \n",
       "34788  zune car kit works great long cord player does...  0.028711  0.040759   \n",
       "34789  zune gb digital media player browni bought g z...  0.047650 -0.007008   \n",
       "34790  zune going ever kill ipod certainly mean zune ...  0.014281  0.008538   \n",
       "34791  zune great product standard wifi separates pac...  0.007662  0.032139   \n",
       "34792  zune hd didnt workwith old docking station lis... -0.139160  0.066938   \n",
       "34793  zune mp player great car packed big rip dollar...  0.054129 -0.008754   \n",
       "34794  zune must sound great small unit plug power pl...  0.020793  0.068935   \n",
       "34795  zune vs ipod ipod wins ipod gb evertying need ... -0.039280  0.017532   \n",
       "34796  zvm awesome great battery life awesome picture...  0.039355  0.027533   \n",
       "\n",
       "            v_2       v_3       v_4       v_5       v_6       v_7       v_8  \\\n",
       "0     -0.144531  0.138062 -0.192871 -0.048706  0.055237 -0.057617  0.078056   \n",
       "1      0.044373  0.208903 -0.009644 -0.065979  0.003011 -0.048177  0.126119   \n",
       "2      0.033649  0.139526 -0.066444 -0.003199  0.100611 -0.106558  0.051306   \n",
       "3     -0.025433  0.097164 -0.119775  0.006975  0.025415 -0.034370  0.111130   \n",
       "4     -0.045933  0.111139 -0.089738  0.034531  0.025286 -0.031473  0.104483   \n",
       "5     -0.067943  0.111421 -0.030667  0.059219 -0.016188 -0.026700  0.091071   \n",
       "6      0.027363  0.069319 -0.054742 -0.000350  0.023708 -0.038602  0.098650   \n",
       "7      0.002321  0.073076 -0.047072 -0.033643  0.121501 -0.050765  0.059246   \n",
       "8     -0.071152  0.068101 -0.107983  0.025496  0.085796  0.017484  0.058860   \n",
       "9     -0.028167  0.068418 -0.073675  0.044399  0.040515 -0.000461  0.099046   \n",
       "10    -0.012636  0.082138 -0.020368 -0.036176 -0.016623 -0.079625  0.121386   \n",
       "11    -0.008753  0.058633 -0.023907 -0.026045  0.047172 -0.014955  0.079577   \n",
       "12    -0.029696  0.090036 -0.042757  0.058603  0.084261 -0.002732 -0.001372   \n",
       "13    -0.033022  0.055564 -0.075318  0.031102  0.043374 -0.050327  0.125891   \n",
       "14    -0.013144  0.063639 -0.093198  0.018579  0.033560 -0.045786  0.121369   \n",
       "15    -0.010939  0.068421 -0.094533  0.044288  0.004297 -0.030450  0.117626   \n",
       "16    -0.022040  0.121102 -0.128143  0.037543  0.033583  0.010905  0.150092   \n",
       "17    -0.011024  0.082934 -0.067627  0.071526  0.039078 -0.041992  0.128755   \n",
       "18    -0.052711  0.090633 -0.068884  0.070465  0.024548  0.030472  0.146492   \n",
       "19    -0.047935  0.091465  0.005748 -0.014923  0.081959 -0.073714  0.210249   \n",
       "20    -0.066195  0.100964 -0.047338  0.024818  0.045089 -0.056210  0.088492   \n",
       "21     0.005639  0.080635 -0.095427  0.040570  0.014280 -0.010490  0.131360   \n",
       "22    -0.021227  0.047969 -0.132310  0.019752  0.052015  0.002305  0.101305   \n",
       "23     0.048196  0.112195 -0.086381  0.048983  0.000936 -0.069791  0.108010   \n",
       "24     0.011501  0.164429 -0.018637  0.016395  0.038505 -0.064277  0.100774   \n",
       "25     0.030759  0.084023 -0.008800  0.018059  0.082522 -0.108492  0.103766   \n",
       "26     0.004917  0.061349 -0.098677 -0.016404  0.108911 -0.097591  0.079424   \n",
       "27     0.085245  0.160323 -0.048871  0.075696  0.069921 -0.070930  0.075579   \n",
       "28     0.006825  0.131553 -0.061199  0.047167  0.036140 -0.089689  0.103026   \n",
       "29     0.162671  0.061792 -0.088306  0.050275  0.032104 -0.087463  0.186609   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "34767  0.008462  0.067646 -0.087794 -0.005525  0.051457 -0.028618  0.120065   \n",
       "34768  0.013986  0.137081 -0.115182  0.013979 -0.003676 -0.116390  0.104632   \n",
       "34769 -0.000815  0.126345 -0.075515  0.080048  0.002162 -0.028190  0.068242   \n",
       "34770  0.009930  0.009046 -0.065233 -0.019677  0.044844 -0.071700  0.098337   \n",
       "34771 -0.046653  0.097812 -0.041171  0.007724  0.010354 -0.064387  0.021217   \n",
       "34772  0.009049  0.090580 -0.064023 -0.007692  0.075535 -0.049143  0.092858   \n",
       "34773 -0.049758  0.097137 -0.010087  0.034071  0.051547 -0.094139  0.080655   \n",
       "34774 -0.019354  0.073366 -0.040090  0.052756  0.056303 -0.060222  0.122628   \n",
       "34775  0.001913  0.075754 -0.057659  0.017126  0.072103 -0.067352  0.122282   \n",
       "34776  0.077990  0.175729 -0.106036  0.075500  0.059278 -0.115252  0.082424   \n",
       "34777  0.014566  0.113055 -0.047736 -0.010160  0.047210 -0.085002  0.094403   \n",
       "34778 -0.005850  0.078904 -0.065312 -0.023386  0.019076 -0.050885  0.092969   \n",
       "34779  0.000593  0.072539 -0.076296  0.015354  0.060406 -0.056730  0.091036   \n",
       "34780  0.031960  0.043466 -0.104222  0.002357  0.071554 -0.031226  0.082872   \n",
       "34781 -0.038865  0.061556 -0.092369 -0.006621  0.026746 -0.072546  0.077394   \n",
       "34782  0.032795  0.024078 -0.032990 -0.040329  0.013889 -0.082550  0.164368   \n",
       "34783 -0.032153  0.081862 -0.095413 -0.024264  0.015066 -0.022748  0.051726   \n",
       "34784  0.011402  0.027219 -0.016163 -0.093073 -0.053855 -0.068112  0.144487   \n",
       "34785 -0.013937  0.112403 -0.131863  0.007321  0.057352 -0.006310  0.086218   \n",
       "34786 -0.006054  0.043668  0.000302  0.049710  0.087128 -0.045872  0.056674   \n",
       "34787 -0.021112  0.057929 -0.090697 -0.004489  0.069613 -0.080835  0.076053   \n",
       "34788 -0.110095  0.057013 -0.008765  0.054980  0.050433 -0.062280  0.152319   \n",
       "34789 -0.035047  0.132695 -0.014673 -0.027512  0.012618 -0.077223  0.054590   \n",
       "34790 -0.000071  0.094696 -0.067215  0.022746  0.061460 -0.064959  0.086824   \n",
       "34791 -0.025463  0.086248 -0.025021  0.038183  0.024434 -0.052218  0.097845   \n",
       "34792 -0.049247 -0.058123 -0.047137  0.014212 -0.059256 -0.023455  0.175886   \n",
       "34793 -0.023944  0.094769 -0.090864  0.003104  0.054158 -0.019110  0.138644   \n",
       "34794  0.006104  0.027381 -0.089518 -0.049292  0.081873 -0.107031  0.126619   \n",
       "34795  0.035322  0.112244 -0.003090  0.071924 -0.004925 -0.054319  0.054321   \n",
       "34796 -0.018950  0.066889 -0.029663  0.002948  0.040856 -0.079338  0.108608   \n",
       "\n",
       "         ...         v_291     v_292     v_293     v_294     v_295     v_296  \\\n",
       "0        ...      0.126587 -0.040558 -0.037659 -0.080322  0.028625  0.095215   \n",
       "1        ...      0.062398 -0.106160  0.027425 -0.084310  0.036051 -0.075643   \n",
       "2        ...      0.051652 -0.137921  0.049885 -0.026442  0.019259 -0.046023   \n",
       "3        ...      0.098162 -0.056672  0.011393 -0.019860  0.048861  0.043048   \n",
       "4        ...      0.070307 -0.074852  0.026937  0.014610 -0.032774  0.024424   \n",
       "5        ...     -0.002268 -0.084671  0.074480  0.060994  0.045754  0.005973   \n",
       "6        ...      0.096301 -0.093292  0.024289 -0.014452 -0.000065 -0.030175   \n",
       "7        ...      0.042418 -0.058828  0.031896 -0.007437  0.040856  0.022322   \n",
       "8        ...      0.068588 -0.047434  0.007011 -0.054970  0.005835  0.013304   \n",
       "9        ...      0.079787 -0.081374  0.018595  0.009227  0.033213  0.021077   \n",
       "10       ...      0.037979 -0.098474 -0.012189 -0.045479 -0.076596 -0.014171   \n",
       "11       ...      0.075301 -0.088116  0.086619 -0.005171 -0.006553 -0.039348   \n",
       "12       ...      0.118756 -0.092172 -0.023658 -0.040213  0.093055  0.066826   \n",
       "13       ...      0.050729 -0.058823  0.033557  0.008474 -0.009779 -0.040835   \n",
       "14       ...      0.104656 -0.041385  0.000911  0.021921 -0.000157 -0.028833   \n",
       "15       ...      0.083125 -0.037606  0.009141 -0.044660 -0.072666 -0.032037   \n",
       "16       ...      0.080160 -0.105442 -0.028581 -0.022569 -0.087402  0.099598   \n",
       "17       ...      0.093194 -0.043064 -0.007117 -0.003771 -0.005039  0.003320   \n",
       "18       ...      0.117203 -0.053675 -0.007717 -0.049055  0.026619  0.016911   \n",
       "19       ...      0.140392 -0.070002 -0.012031 -0.013320 -0.071578  0.001692   \n",
       "20       ...      0.098445 -0.075636  0.078938  0.002370  0.035747  0.010918   \n",
       "21       ...      0.035467 -0.071520  0.017265  0.031680 -0.066958 -0.043677   \n",
       "22       ...      0.087597 -0.040086  0.026738 -0.015471  0.007370  0.024111   \n",
       "23       ...      0.124878 -0.120073 -0.022411 -0.024893  0.008856  0.023343   \n",
       "24       ...      0.119902 -0.124180  0.053363 -0.031176 -0.046389 -0.005890   \n",
       "25       ...      0.078985 -0.094000  0.009201 -0.048680 -0.049529 -0.011748   \n",
       "26       ...      0.050925 -0.105010  0.062230 -0.022301 -0.001543  0.020740   \n",
       "27       ...      0.129371 -0.108714  0.020185 -0.049255  0.026590 -0.011834   \n",
       "28       ...      0.044173 -0.100709  0.063453 -0.036738 -0.026992 -0.022626   \n",
       "29       ...      0.136401 -0.130310  0.098193 -0.103418 -0.080054 -0.167889   \n",
       "...      ...           ...       ...       ...       ...       ...       ...   \n",
       "34767    ...      0.071538 -0.094381  0.035824 -0.005061 -0.004824 -0.021120   \n",
       "34768    ...      0.032445 -0.058027  0.014134  0.018408 -0.102332  0.013029   \n",
       "34769    ...      0.044999 -0.072095  0.039203 -0.031009 -0.033953 -0.006565   \n",
       "34770    ...      0.026912 -0.070269  0.029600  0.010015  0.034080 -0.011732   \n",
       "34771    ...      0.101962 -0.070512 -0.016635  0.007263  0.012218 -0.010347   \n",
       "34772    ...      0.077107 -0.064206  0.033620 -0.017860 -0.012943 -0.019096   \n",
       "34773    ...      0.056744 -0.082675  0.024254  0.011996  0.014679  0.038161   \n",
       "34774    ...      0.087784 -0.111983  0.029608  0.003076  0.009319 -0.014374   \n",
       "34775    ...      0.091741 -0.083823  0.013420  0.020614  0.002415 -0.011846   \n",
       "34776    ...      0.081569 -0.083653  0.029646 -0.068146 -0.022243 -0.036970   \n",
       "34777    ...      0.096181 -0.094916  0.019352 -0.006526 -0.042887 -0.006099   \n",
       "34778    ...      0.040601 -0.094226 -0.006702  0.004376 -0.005781 -0.026966   \n",
       "34779    ...      0.037841 -0.054450  0.032823 -0.035525 -0.005281 -0.000907   \n",
       "34780    ...     -0.011369 -0.002645  0.008965 -0.009766 -0.022542 -0.009155   \n",
       "34781    ...      0.054107 -0.095642  0.064771 -0.002058  0.014141  0.001459   \n",
       "34782    ...      0.050056 -0.096527 -0.091064 -0.042023 -0.045837 -0.102982   \n",
       "34783    ...      0.012731 -0.079164 -0.039678 -0.017563 -0.049942 -0.011913   \n",
       "34784    ...     -0.000366 -0.157515  0.020819  0.010271  0.011852  0.048473   \n",
       "34785    ...      0.094746 -0.122875  0.071018 -0.083595  0.056171  0.057771   \n",
       "34786    ...      0.127252 -0.122766 -0.025705 -0.072832 -0.012993 -0.066641   \n",
       "34787    ...      0.065187 -0.071268  0.021169 -0.028572 -0.029418  0.001714   \n",
       "34788    ...      0.181738 -0.092200 -0.040613 -0.044055 -0.082556 -0.066479   \n",
       "34789    ...      0.072247 -0.136762 -0.063020 -0.014724 -0.018133 -0.016571   \n",
       "34790    ...      0.071584 -0.086563  0.005348  0.005328 -0.020138 -0.024963   \n",
       "34791    ...      0.096530 -0.105378 -0.001525  0.012382 -0.001765 -0.031386   \n",
       "34792    ...      0.154576 -0.075631  0.147339  0.125083 -0.013323 -0.136326   \n",
       "34793    ...      0.092615 -0.086169  0.033205 -0.031981 -0.012948 -0.028467   \n",
       "34794    ...      0.092957 -0.111749 -0.031160 -0.049593 -0.033134 -0.023336   \n",
       "34795    ...      0.077744 -0.079247 -0.005413 -0.002078 -0.023064 -0.034286   \n",
       "34796    ...      0.060601 -0.112941  0.005772  0.007942 -0.021951  0.010903   \n",
       "\n",
       "          v_297     v_298     v_299  sentiment  \n",
       "0      0.017071  0.132107 -0.121521          0  \n",
       "1     -0.018814 -0.064189 -0.029114          0  \n",
       "2     -0.059559  0.020724 -0.000488          0  \n",
       "3     -0.044175  0.025990  0.033907          1  \n",
       "4     -0.074364  0.001452  0.008260          1  \n",
       "5     -0.031968  0.058440 -0.031531          1  \n",
       "6     -0.051252  0.017638 -0.043039          0  \n",
       "7     -0.041686 -0.012453 -0.050984          1  \n",
       "8     -0.048201 -0.011558  0.021614          0  \n",
       "9     -0.017888  0.026420 -0.028648          0  \n",
       "10    -0.042561  0.005516 -0.008649          1  \n",
       "11    -0.086576  0.059854 -0.057777          1  \n",
       "12    -0.035722  0.049307 -0.027960          0  \n",
       "13    -0.061705 -0.017015  0.000755          0  \n",
       "14    -0.070976  0.004203 -0.012090          1  \n",
       "15    -0.063754 -0.002800 -0.030479          0  \n",
       "16    -0.030440 -0.010078 -0.027364          1  \n",
       "17    -0.042482 -0.020845 -0.066370          0  \n",
       "18    -0.011801 -0.004809 -0.026752          0  \n",
       "19    -0.028040 -0.064819 -0.072766          1  \n",
       "20    -0.035720 -0.019829 -0.023923          1  \n",
       "21    -0.092289  0.013270 -0.051235          0  \n",
       "22    -0.080407 -0.027701 -0.007273          1  \n",
       "23    -0.065211 -0.033089 -0.024081          0  \n",
       "24    -0.043967 -0.005890 -0.003734          1  \n",
       "25    -0.073848 -0.005879  0.012812          1  \n",
       "26    -0.020040 -0.016801 -0.023660          0  \n",
       "27    -0.073357  0.015717 -0.067197          0  \n",
       "28    -0.046516 -0.011953 -0.024378          0  \n",
       "29    -0.036841 -0.032014 -0.042334          0  \n",
       "...         ...       ...       ...        ...  \n",
       "34767 -0.046655  0.010087 -0.021604          0  \n",
       "34768 -0.100739 -0.045509  0.065447          0  \n",
       "34769 -0.056584 -0.071555 -0.006239          1  \n",
       "34770 -0.035811  0.007553 -0.048554          0  \n",
       "34771 -0.081476 -0.008478 -0.011142          1  \n",
       "34772 -0.040716  0.001065 -0.007850          0  \n",
       "34773  0.068848  0.036186  0.008362          0  \n",
       "34774 -0.061617 -0.013711  0.002659          0  \n",
       "34775 -0.016748 -0.010047  0.024644          1  \n",
       "34776 -0.065376 -0.039999  0.019741          0  \n",
       "34777 -0.055725 -0.002411 -0.009177          0  \n",
       "34778 -0.032470  0.018134 -0.020711          1  \n",
       "34779 -0.040174  0.006884 -0.013464          0  \n",
       "34780 -0.105594 -0.023554 -0.089084          1  \n",
       "34781 -0.021227  0.005993  0.015430          0  \n",
       "34782 -0.042084  0.017319 -0.019782          0  \n",
       "34783 -0.037494 -0.025953 -0.001141          1  \n",
       "34784 -0.080202  0.034965 -0.036249          0  \n",
       "34785 -0.024498  0.025323  0.021719          0  \n",
       "34786 -0.125533 -0.076284  0.042737          1  \n",
       "34787 -0.050574 -0.007882 -0.019224          1  \n",
       "34788 -0.021967 -0.048391 -0.032843          1  \n",
       "34789 -0.119292  0.020632 -0.023275          1  \n",
       "34790 -0.062509 -0.015372 -0.004787          1  \n",
       "34791 -0.078421 -0.043864 -0.014908          1  \n",
       "34792 -0.092215 -0.023908  0.023525          0  \n",
       "34793 -0.075935  0.014572 -0.021138          0  \n",
       "34794 -0.040609 -0.079118 -0.013694          1  \n",
       "34795 -0.085489 -0.062325  0.050823          1  \n",
       "34796 -0.091358 -0.019241 -0.021855          1  \n",
       "\n",
       "[34797 rows x 302 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Represent reviews as average of words embeddings\n",
    "\n",
    "all_review = []\n",
    "all_unigram = []\n",
    "\n",
    "for a in data['reviews']:\n",
    "    unigram = []\n",
    "    review = []\n",
    "    unigram = a.split()\n",
    "    review = [a] * len(unigram)\n",
    "    all_review.extend(review)\n",
    "    all_unigram.extend(unigram)\n",
    "\n",
    "\n",
    "df_unigram = pd.DataFrame({'reviews': all_review, 'token': all_unigram})\n",
    "df_unigram = pd.merge(data, df_unigram, how='right', on=['reviews'])\n",
    "df_unigram = df_unigram.drop_duplicates(subset = ['reviews','token'])\n",
    "df_unigram = pd.merge(embeddings_vocab, df_unigram, how='right', on=['token']).dropna()\n",
    "df_unigram = df_unigram.groupby(['reviews'],as_index = False).mean()\n",
    "df_unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Simple Classifier ‚Äì From word representation to modeling </h2> </font> \n",
    "**Linear SVM and Logistic Based Classification**\n",
    "* Pre-processing converts words to features and creates new features based on word count\n",
    "* Text vectorization  outputs  the features to numerical vectors. Ex count vectors, TF-IDF vectors\n",
    "* For classification problems, vector spaced based ML methods can be applied to find decision boundary between two classes .  Notable example SVM.\n",
    "* Linear SVM defines the criterion that maximally separates the two classes, allowing users to adjust cost and penalty parameters on misclassification to suit business problems.\n",
    "<img src=\"images/SVM_hyperplane.png\", width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split the dataset to train and test (80% for training and 20% for testing)\n",
    "\n",
    "## Fit the linear SVC on the training data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(df_unigram[df_unigram.columns[1:301]],df_unigram['sentiment'],test_size=0.2)\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 83.29% correctly from the test dataset \n"
     ]
    }
   ],
   "source": [
    "# Test the Linar SVC model on the test data\n",
    "# WE use the accuracy defined as ratio of correctly predicted data by the overall data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Test_predictions = clf.predict(Test_X)\n",
    "print(\"The model predicted {0:.2f}% correctly from the test dataset \".format(accuracy_score(Test_Y,Test_predictions)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Cassify the sentiment of your own review using the linear SVC model! </h2> </font> \n",
    "The linear SVM is able to correctly classify **83.29%** of the amazon test dataset reviews.\n",
    "<br/>\n",
    "You can use the function below to find out what the model thinks of your review!!\n",
    "\n",
    "1) Write your review\n",
    "\n",
    "2) Preprocess your review\n",
    "\n",
    "3) Call the function get_svc_class(my_processed_review) to ge the result of the SVM model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Classify the sentiment of my comment\n",
    "import numpy as np\n",
    "def get_svc_class(my_processed_review):\n",
    "    avg_embed = []\n",
    "    for i in my_processed_review.split():\n",
    "        if i in embeddings_vocab['token'].values:\n",
    "            avg_embed.append(embeddings_vocab[embeddings_vocab['token']=='happy'].values[0][1:])\n",
    "    my_prediction = clf.predict(np.mean(avg_embed,axis=0).reshape(1, -1))\n",
    "    if my_prediction == 1:\n",
    "        print('The model predicted that the review is positive')\n",
    "    else:\n",
    "        print('The model predicted that the review is negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted that the review is positive\n"
     ]
    }
   ],
   "source": [
    "get_svc_class(processed_positive_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'> <h2> Neural Network classifier- Convolution neural networks</h2> </font> \n",
    "* Traditionally, CNNs are used to analyze images and are made up of one or more convolutional layers.\n",
    "\n",
    "* Main idea here is to use multiple filters of different sizes that can look at bi-grams, tri-grams, n-grams.\n",
    "\n",
    "* Fast to train, works well, but fails to capture longer dependencies.\n",
    "\n",
    "<img src=\"images/CNN.png\", width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Activation, Conv2D, Input, Embedding, Reshape, MaxPool2D, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# make the max word length to be constant\n",
    "MAX_WORDS = embeddings_vocab.shape[0]\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 300\n",
    "filter_sizes = [1,2,3]\n",
    "num_filters = 20\n",
    "drop = 0.3\n",
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words : 81816\n"
     ]
    }
   ],
   "source": [
    "tokenizer  = Tokenizer(num_words = MAX_WORDS)\n",
    "tokenizer.fit_on_texts(data['reviews'])\n",
    "sequences =  tokenizer.texts_to_sequences(data['reviews'])\n",
    "word_index = tokenizer.word_index\n",
    "print(\"unique words : {}\".format(len(word_index)))\n",
    "data_padded = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "## Split data to train, validation and test\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(data_padded, data['sentiment'],test_size=0.2)\n",
    "Train_X, Val_X, Train_Y, Val_Y = train_test_split(Train_X, Train_Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## Create embeddings Matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in embeddings_vocab['token'].values:\n",
    "        embedding_matrix[i] = embeddings_vocab[embeddings_vocab['token']==word].values[0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0515 13:41:46.073524 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0515 13:41:46.195762 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0515 13:41:46.215281 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0515 13:41:46.253854 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0515 13:41:46.255744 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0515 13:41:46.971519 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0515 13:41:47.021418 139666106832704 deprecation.py:506] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200, 300)\n",
      "(?, 200, 300, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0515 13:41:47.138987 139666106832704 deprecation_wrapper.py:119] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0515 13:41:47.166006 139666106832704 deprecation.py:323] From /apps/cmor/dsai_local/anaconda/envs/DSAI02-ML-DevEnv01/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 300)     24545100    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 200, 300, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 200, 1, 20)   6020        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 199, 1, 20)   12020       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 198, 1, 20)   18020       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 20)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 20)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 60)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            61          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,581,221\n",
      "Trainable params: 36,121\n",
      "Non-trainable params: 24,545,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "print(embedding.shape)\n",
    "reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "print(reshape.shape)\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(1,activation = 'sigmoid')(dropout)\n",
    "# this creates a model that includes\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "checkpoint = ModelCheckpoint('weights_cnn_sentece.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22400 samples, validate on 5600 samples\n",
      "Epoch 1/20\n",
      "22400/22400 [==============================] - 18s 821us/step - loss: 0.4007 - acc: 0.8188 - val_loss: 0.3269 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85429, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 2/20\n",
      "22400/22400 [==============================] - 17s 740us/step - loss: 0.3235 - acc: 0.8626 - val_loss: 0.3133 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85429 to 0.86714, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 3/20\n",
      "22400/22400 [==============================] - 15s 688us/step - loss: 0.2957 - acc: 0.8780 - val_loss: 0.3098 - val_acc: 0.8759\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86714 to 0.87589, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 4/20\n",
      "22400/22400 [==============================] - 17s 740us/step - loss: 0.2719 - acc: 0.8883 - val_loss: 0.3186 - val_acc: 0.8716\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87589\n",
      "Epoch 5/20\n",
      "22400/22400 [==============================] - 16s 734us/step - loss: 0.2506 - acc: 0.8989 - val_loss: 0.3104 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87589 to 0.88125, saving model to weights_cnn_sentece.hdf5\n",
      "Epoch 6/20\n",
      "22400/22400 [==============================] - 15s 667us/step - loss: 0.2338 - acc: 0.9052 - val_loss: 0.3185 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.88125\n",
      "Epoch 7/20\n",
      "22400/22400 [==============================] - 10s 467us/step - loss: 0.2168 - acc: 0.9122 - val_loss: 0.3318 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.88125\n",
      "Epoch 8/20\n",
      "22400/22400 [==============================] - 10s 441us/step - loss: 0.2061 - acc: 0.9186 - val_loss: 0.3424 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.88125\n",
      "Epoch 9/20\n",
      "22400/22400 [==============================] - 9s 385us/step - loss: 0.1936 - acc: 0.9237 - val_loss: 0.3539 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.88125\n",
      "Epoch 10/20\n",
      "22400/22400 [==============================] - 8s 353us/step - loss: 0.1794 - acc: 0.9276 - val_loss: 0.3677 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.88125\n",
      "Epoch 11/20\n",
      "22400/22400 [==============================] - 8s 350us/step - loss: 0.1747 - acc: 0.9321 - val_loss: 0.3882 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.88125\n",
      "Epoch 12/20\n",
      "22400/22400 [==============================] - 7s 328us/step - loss: 0.1746 - acc: 0.9333 - val_loss: 0.3895 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.88125\n",
      "Epoch 13/20\n",
      "22400/22400 [==============================] - 7s 303us/step - loss: 0.1549 - acc: 0.9388 - val_loss: 0.4014 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.88125\n",
      "Epoch 14/20\n",
      "22400/22400 [==============================] - 7s 296us/step - loss: 0.1519 - acc: 0.9413 - val_loss: 0.4231 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.88125\n",
      "Epoch 15/20\n",
      "22400/22400 [==============================] - 6s 272us/step - loss: 0.1546 - acc: 0.9398 - val_loss: 0.4068 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.88125\n",
      "Epoch 16/20\n",
      "22400/22400 [==============================] - 6s 265us/step - loss: 0.1428 - acc: 0.9438 - val_loss: 0.4184 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.88125\n",
      "Epoch 17/20\n",
      "22400/22400 [==============================] - 6s 268us/step - loss: 0.1401 - acc: 0.9442 - val_loss: 0.4183 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.88125\n",
      "Epoch 18/20\n",
      "22400/22400 [==============================] - 6s 253us/step - loss: 0.1346 - acc: 0.9489 - val_loss: 0.4399 - val_acc: 0.8632\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.88125\n",
      "Epoch 19/20\n",
      "22400/22400 [==============================] - 5s 225us/step - loss: 0.1306 - acc: 0.9517 - val_loss: 0.4624 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88125\n",
      "Epoch 20/20\n",
      "22400/22400 [==============================] - 5s 209us/step - loss: 0.1297 - acc: 0.9529 - val_loss: 0.4428 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Train_X, Train_Y, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(Val_X, Val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('weights_cnn_sentece.hdf5')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 87.77% correctly from the test dataset \n"
     ]
    }
   ],
   "source": [
    "print(\"The model predicted {0:.2f}% correctly from the test dataset \".format(accuracy_score(Test_Y, (model.predict(Test_X) > 0.5).astype(int))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
